{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "### CSC 478\n",
    "#### Kristen Groom\n",
    "#### 5/11/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Linear Regression [Dataset: communities.zip]\n",
    "For this problem you will experiment with linear regression models to make predictions with numerical data. You will also explore more systematic methods for feature selection and for optimizing model parameters (model selection). The data set you will use is a subset of the \"Communities and Crime\" data set that combines information from the 1990 census data as well as FBI crime data from 1995. Please read the full description of the data, including the description and statistics on different variables. The target attribute for regression purposes is \"ViolentCrimesPerPop\". The two identifier attributes \"state\" and \"community name\" should be excluded for the regression task.\n",
    "\n",
    "Your tasks in this problem are the following [Note: for these tasks you will use the available linear-models from scikit-learn as well as the implementations of the relevant approaches from the Ch. 8 of MLA] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Load and preprocess the data using Pandas or Numpy and, if necessary, preprocessing functions from scikit-learn. The provided data is already normalized (see description), so there is no need for additional normalization. Compute and display basic statistics (mean, standard deviation, min, max, etc.) for each of the variables in the data set. Separate the target attribute for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed for our Linear Regression tasks\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first task is to read in the data:\n",
    "# reading in the training data as a pandas DataFrame:\n",
    "communities_matrix = pd.read_csv(\"communities/communities.csv\", na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SouthPasadenacity</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>Lincolntown</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Selmacity</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>Hendersoncity</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>Claytoncity</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "5      6    SouthPasadenacity        0.02           0.28          0.06   \n",
       "6     44          Lincolntown        0.01           0.39          0.00   \n",
       "7      6            Selmacity        0.01           0.74          0.03   \n",
       "8     21        Hendersoncity        0.03           0.34          0.20   \n",
       "9     29          Claytoncity        0.01           0.40          0.06   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47   \n",
       "1          0.74          0.45         0.07         0.26         0.59   \n",
       "2          0.56          0.17         0.04         0.39         0.47   \n",
       "3          0.08          0.12         0.10         0.51         0.50   \n",
       "4          0.95          0.09         0.05         0.38         0.38   \n",
       "5          0.54          1.00         0.25         0.31         0.48   \n",
       "6          0.98          0.06         0.02         0.30         0.37   \n",
       "7          0.46          0.20         1.00         0.52         0.55   \n",
       "8          0.84          0.02         0.00         0.38         0.45   \n",
       "9          0.87          0.30         0.03         0.90         0.82   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "5         ...                 0.0            0.70              0.42   \n",
       "6         ...                 0.0            0.15              0.81   \n",
       "7         ...                 0.0            0.59              0.58   \n",
       "8         ...                 0.0            0.01              0.78   \n",
       "9         ...                 0.0            0.22              0.42   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "5            0.49           0.73            0.64      0.01     0.58   \n",
       "6            0.77           0.91            0.84      0.05     0.08   \n",
       "7            0.52           0.79            0.78      0.01     0.33   \n",
       "8            0.48           0.79            0.75      0.04     0.17   \n",
       "9            0.34           0.23            0.09      0.00     0.47   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "5            0.10                 0.14  \n",
       "6            0.06                 0.03  \n",
       "7            0.00                 0.55  \n",
       "8            0.04                 0.53  \n",
       "9            0.11                 0.15  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can remove state and communityname from our data b/c we will not be using this information\n",
    "communities_matrix.drop(['state', 'communityname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12   \n",
       "1        0.00           0.16          0.12          0.74          0.45   \n",
       "2        0.00           0.42          0.49          0.56          0.17   \n",
       "3        0.04           0.77          1.00          0.08          0.12   \n",
       "4        0.01           0.55          0.02          0.95          0.09   \n",
       "5        0.02           0.28          0.06          0.54          1.00   \n",
       "6        0.01           0.39          0.00          0.98          0.06   \n",
       "7        0.01           0.74          0.03          0.46          0.20   \n",
       "8        0.03           0.34          0.20          0.84          0.02   \n",
       "9        0.01           0.40          0.06          0.87          0.30   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.17         0.34         0.47         0.29        0.32   \n",
       "1         0.07         0.26         0.59         0.35        0.27   \n",
       "2         0.04         0.39         0.47         0.28        0.32   \n",
       "3         0.10         0.51         0.50         0.34        0.21   \n",
       "4         0.05         0.38         0.38         0.23        0.36   \n",
       "5         0.25         0.31         0.48         0.27        0.37   \n",
       "6         0.02         0.30         0.37         0.23        0.60   \n",
       "7         1.00         0.52         0.55         0.36        0.35   \n",
       "8         0.00         0.38         0.45         0.28        0.48   \n",
       "9         0.03         0.90         0.82         0.80        0.39   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "5         ...                 0.0            0.70              0.42   \n",
       "6         ...                 0.0            0.15              0.81   \n",
       "7         ...                 0.0            0.59              0.58   \n",
       "8         ...                 0.0            0.01              0.78   \n",
       "9         ...                 0.0            0.22              0.42   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "5            0.49           0.73            0.64      0.01     0.58   \n",
       "6            0.77           0.91            0.84      0.05     0.08   \n",
       "7            0.52           0.79            0.78      0.01     0.33   \n",
       "8            0.48           0.79            0.75      0.04     0.17   \n",
       "9            0.34           0.23            0.09      0.00     0.47   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "5            0.10                 0.14  \n",
       "6            0.06                 0.03  \n",
       "7            0.00                 0.55  \n",
       "8            0.04                 0.53  \n",
       "9            0.11                 0.15  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holding column names for the visualization of regression coefficients that I'll complete in steps below\n",
    "# after finding the weights\n",
    "feature_names = list(communities_matrix.columns.values) # gives the column names or feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Statistics of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctHisp</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t21</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t29</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct16t24</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.336264</td>\n",
       "      <td>0.166505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct65up</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.423164</td>\n",
       "      <td>0.179185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbUrban</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.064072</td>\n",
       "      <td>0.128256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctUrban</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.696269</td>\n",
       "      <td>0.444811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medIncome</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.361123</td>\n",
       "      <td>0.209362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWWage</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.558154</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.291570</td>\n",
       "      <td>0.204108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWInvInc</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.495687</td>\n",
       "      <td>0.178071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWSocSec</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.471133</td>\n",
       "      <td>0.173619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.222137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWRetire</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.479248</td>\n",
       "      <td>0.167564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medFamInc</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.375677</td>\n",
       "      <td>0.198257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perCapInc</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.191109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitePerCap</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.368049</td>\n",
       "      <td>0.186804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackPerCap</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.291098</td>\n",
       "      <td>0.171593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indianPerCap</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.203506</td>\n",
       "      <td>0.164775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AsianPerCap</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.322357</td>\n",
       "      <td>0.195411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherPerCap</th>\n",
       "      <td>1993.0</td>\n",
       "      <td>0.284742</td>\n",
       "      <td>0.191008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HispPerCap</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.386279</td>\n",
       "      <td>0.183081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumUnderPov</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.055507</td>\n",
       "      <td>0.127941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.303024</td>\n",
       "      <td>0.228474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.315807</td>\n",
       "      <td>0.213360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedNumBR</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.314694</td>\n",
       "      <td>0.255182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HousVacant</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.076815</td>\n",
       "      <td>0.150465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOccup</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.719549</td>\n",
       "      <td>0.194024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.548686</td>\n",
       "      <td>0.185204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.204529</td>\n",
       "      <td>0.217770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.433335</td>\n",
       "      <td>0.188986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.494178</td>\n",
       "      <td>0.232467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.264478</td>\n",
       "      <td>0.242847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.243059</td>\n",
       "      <td>0.206295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.264689</td>\n",
       "      <td>0.224425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.263490</td>\n",
       "      <td>0.231542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.268942</td>\n",
       "      <td>0.235252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentLowQ</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.346379</td>\n",
       "      <td>0.219323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentMedian</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.372457</td>\n",
       "      <td>0.209278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentHighQ</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.422964</td>\n",
       "      <td>0.248286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRent</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.384102</td>\n",
       "      <td>0.213404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.490125</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.449754</td>\n",
       "      <td>0.187274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.403816</td>\n",
       "      <td>0.192593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInShelters</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.102607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumStreet</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctBornSameState</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameCity85</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameState85</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandArea</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PopDens</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.237979</td>\n",
       "      <td>0.232985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count      mean       std  min     25%    50%     75%  \\\n",
       "population             1994.0  0.057593  0.126906  0.0  0.0100  0.020  0.0500   \n",
       "householdsize          1994.0  0.463395  0.163717  0.0  0.3500  0.440  0.5400   \n",
       "racepctblack           1994.0  0.179629  0.253442  0.0  0.0200  0.060  0.2300   \n",
       "racePctWhite           1994.0  0.753716  0.244039  0.0  0.6300  0.850  0.9400   \n",
       "racePctAsian           1994.0  0.153681  0.208877  0.0  0.0400  0.070  0.1700   \n",
       "racePctHisp            1994.0  0.144022  0.232492  0.0  0.0100  0.040  0.1600   \n",
       "agePct12t21            1994.0  0.424218  0.155196  0.0  0.3400  0.400  0.4700   \n",
       "agePct12t29            1994.0  0.493867  0.143564  0.0  0.4100  0.480  0.5400   \n",
       "agePct16t24            1994.0  0.336264  0.166505  0.0  0.2500  0.290  0.3600   \n",
       "agePct65up             1994.0  0.423164  0.179185  0.0  0.3000  0.420  0.5300   \n",
       "numbUrban              1994.0  0.064072  0.128256  0.0  0.0000  0.030  0.0700   \n",
       "pctUrban               1994.0  0.696269  0.444811  0.0  0.0000  1.000  1.0000   \n",
       "medIncome              1994.0  0.361123  0.209362  0.0  0.2000  0.320  0.4900   \n",
       "pctWWage               1994.0  0.558154  0.182913  0.0  0.4400  0.560  0.6900   \n",
       "pctWFarmSelf           1994.0  0.291570  0.204108  0.0  0.1600  0.230  0.3700   \n",
       "pctWInvInc             1994.0  0.495687  0.178071  0.0  0.3700  0.480  0.6200   \n",
       "pctWSocSec             1994.0  0.471133  0.173619  0.0  0.3500  0.475  0.5800   \n",
       "pctWPubAsst            1994.0  0.317778  0.222137  0.0  0.1425  0.260  0.4400   \n",
       "pctWRetire             1994.0  0.479248  0.167564  0.0  0.3600  0.470  0.5800   \n",
       "medFamInc              1994.0  0.375677  0.198257  0.0  0.2300  0.330  0.4800   \n",
       "perCapInc              1994.0  0.350251  0.191109  0.0  0.2200  0.300  0.4300   \n",
       "whitePerCap            1994.0  0.368049  0.186804  0.0  0.2400  0.320  0.4400   \n",
       "blackPerCap            1994.0  0.291098  0.171593  0.0  0.1725  0.250  0.3800   \n",
       "indianPerCap           1994.0  0.203506  0.164775  0.0  0.1100  0.170  0.2500   \n",
       "AsianPerCap            1994.0  0.322357  0.195411  0.0  0.1900  0.280  0.4000   \n",
       "OtherPerCap            1993.0  0.284742  0.191008  0.0  0.1700  0.250  0.3600   \n",
       "HispPerCap             1994.0  0.386279  0.183081  0.0  0.2600  0.345  0.4800   \n",
       "NumUnderPov            1994.0  0.055507  0.127941  0.0  0.0100  0.020  0.0500   \n",
       "PctPopUnderPov         1994.0  0.303024  0.228474  0.0  0.1100  0.250  0.4500   \n",
       "PctLess9thGrade        1994.0  0.315807  0.213360  0.0  0.1600  0.270  0.4200   \n",
       "...                       ...       ...       ...  ...     ...    ...     ...   \n",
       "MedNumBR               1994.0  0.314694  0.255182  0.0  0.0000  0.500  0.5000   \n",
       "HousVacant             1994.0  0.076815  0.150465  0.0  0.0100  0.030  0.0700   \n",
       "PctHousOccup           1994.0  0.719549  0.194024  0.0  0.6300  0.770  0.8600   \n",
       "PctHousOwnOcc          1994.0  0.548686  0.185204  0.0  0.4300  0.540  0.6700   \n",
       "PctVacantBoarded       1994.0  0.204529  0.217770  0.0  0.0600  0.130  0.2700   \n",
       "PctVacMore6Mos         1994.0  0.433335  0.188986  0.0  0.2900  0.420  0.5600   \n",
       "MedYrHousBuilt         1994.0  0.494178  0.232467  0.0  0.3500  0.520  0.6700   \n",
       "PctHousNoPhone         1994.0  0.264478  0.242847  0.0  0.0600  0.185  0.4200   \n",
       "PctWOFullPlumb         1994.0  0.243059  0.206295  0.0  0.1000  0.190  0.3300   \n",
       "OwnOccLowQuart         1994.0  0.264689  0.224425  0.0  0.0900  0.180  0.4000   \n",
       "OwnOccMedVal           1994.0  0.263490  0.231542  0.0  0.0900  0.170  0.3900   \n",
       "OwnOccHiQuart          1994.0  0.268942  0.235252  0.0  0.0900  0.180  0.3800   \n",
       "RentLowQ               1994.0  0.346379  0.219323  0.0  0.1700  0.310  0.4900   \n",
       "RentMedian             1994.0  0.372457  0.209278  0.0  0.2000  0.330  0.5200   \n",
       "RentHighQ              1994.0  0.422964  0.248286  0.0  0.2200  0.370  0.5900   \n",
       "MedRent                1994.0  0.384102  0.213404  0.0  0.2100  0.340  0.5300   \n",
       "MedRentPctHousInc      1994.0  0.490125  0.169500  0.0  0.3700  0.480  0.5900   \n",
       "MedOwnCostPctInc       1994.0  0.449754  0.187274  0.0  0.3200  0.450  0.5800   \n",
       "MedOwnCostPctIncNoMtg  1994.0  0.403816  0.192593  0.0  0.2500  0.370  0.5100   \n",
       "NumInShelters          1994.0  0.029438  0.102607  0.0  0.0000  0.000  0.0100   \n",
       "NumStreet              1994.0  0.022778  0.100400  0.0  0.0000  0.000  0.0000   \n",
       "PctForeignBorn         1994.0  0.215552  0.231134  0.0  0.0600  0.130  0.2800   \n",
       "PctBornSameState       1994.0  0.608892  0.204329  0.0  0.4700  0.630  0.7775   \n",
       "PctSameHouse85         1994.0  0.535050  0.181352  0.0  0.4200  0.540  0.6600   \n",
       "PctSameCity85          1994.0  0.626424  0.200521  0.0  0.5200  0.670  0.7700   \n",
       "PctSameState85         1994.0  0.651530  0.198221  0.0  0.5600  0.700  0.7900   \n",
       "LandArea               1994.0  0.065231  0.109459  0.0  0.0200  0.040  0.0700   \n",
       "PopDens                1994.0  0.232854  0.203092  0.0  0.1000  0.170  0.2800   \n",
       "PctUsePubTrans         1994.0  0.161685  0.229055  0.0  0.0200  0.070  0.1900   \n",
       "ViolentCrimesPerPop    1994.0  0.237979  0.232985  0.0  0.0700  0.150  0.3300   \n",
       "\n",
       "                       max  \n",
       "population             1.0  \n",
       "householdsize          1.0  \n",
       "racepctblack           1.0  \n",
       "racePctWhite           1.0  \n",
       "racePctAsian           1.0  \n",
       "racePctHisp            1.0  \n",
       "agePct12t21            1.0  \n",
       "agePct12t29            1.0  \n",
       "agePct16t24            1.0  \n",
       "agePct65up             1.0  \n",
       "numbUrban              1.0  \n",
       "pctUrban               1.0  \n",
       "medIncome              1.0  \n",
       "pctWWage               1.0  \n",
       "pctWFarmSelf           1.0  \n",
       "pctWInvInc             1.0  \n",
       "pctWSocSec             1.0  \n",
       "pctWPubAsst            1.0  \n",
       "pctWRetire             1.0  \n",
       "medFamInc              1.0  \n",
       "perCapInc              1.0  \n",
       "whitePerCap            1.0  \n",
       "blackPerCap            1.0  \n",
       "indianPerCap           1.0  \n",
       "AsianPerCap            1.0  \n",
       "OtherPerCap            1.0  \n",
       "HispPerCap             1.0  \n",
       "NumUnderPov            1.0  \n",
       "PctPopUnderPov         1.0  \n",
       "PctLess9thGrade        1.0  \n",
       "...                    ...  \n",
       "MedNumBR               1.0  \n",
       "HousVacant             1.0  \n",
       "PctHousOccup           1.0  \n",
       "PctHousOwnOcc          1.0  \n",
       "PctVacantBoarded       1.0  \n",
       "PctVacMore6Mos         1.0  \n",
       "MedYrHousBuilt         1.0  \n",
       "PctHousNoPhone         1.0  \n",
       "PctWOFullPlumb         1.0  \n",
       "OwnOccLowQuart         1.0  \n",
       "OwnOccMedVal           1.0  \n",
       "OwnOccHiQuart          1.0  \n",
       "RentLowQ               1.0  \n",
       "RentMedian             1.0  \n",
       "RentHighQ              1.0  \n",
       "MedRent                1.0  \n",
       "MedRentPctHousInc      1.0  \n",
       "MedOwnCostPctInc       1.0  \n",
       "MedOwnCostPctIncNoMtg  1.0  \n",
       "NumInShelters          1.0  \n",
       "NumStreet              1.0  \n",
       "PctForeignBorn         1.0  \n",
       "PctBornSameState       1.0  \n",
       "PctSameHouse85         1.0  \n",
       "PctSameCity85          1.0  \n",
       "PctSameState85         1.0  \n",
       "LandArea               1.0  \n",
       "PopDens                1.0  \n",
       "PctUsePubTrans         1.0  \n",
       "ViolentCrimesPerPop    1.0  \n",
       "\n",
       "[98 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_matrix.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above, at first glance, I do not see whether there are no null values because the counts are equal to the number of vectors in the data. Although I will want to check to make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_rows = communities_matrix[communities_matrix.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "130        0.02           0.38          0.98          0.22          0.01   \n",
       "\n",
       "     racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "130         0.01         0.44          0.4         0.27        0.58   \n",
       "\n",
       "            ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "130         ...                 0.0            0.01              0.84   \n",
       "\n",
       "     PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "130             0.7           0.83            0.77      0.04     0.12   \n",
       "\n",
       "     PctUsePubTrans  ViolentCrimesPerPop  \n",
       "130            0.05                 0.23  \n",
       "\n",
       "[1 rows x 98 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so I see that there is 1 row with a null value so I will drop this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_matrix.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [population, householdsize, racepctblack, racePctWhite, racePctAsian, racePctHisp, agePct12t21, agePct12t29, agePct16t24, agePct65up, numbUrban, pctUrban, medIncome, pctWWage, pctWFarmSelf, pctWInvInc, pctWSocSec, pctWPubAsst, pctWRetire, medFamInc, perCapInc, whitePerCap, blackPerCap, indianPerCap, AsianPerCap, OtherPerCap, HispPerCap, NumUnderPov, PctPopUnderPov, PctLess9thGrade, PctNotHSGrad, PctBSorMore, PctUnemployed, PctEmploy, PctEmplManu, PctEmplProfServ, MalePctDivorce, MalePctNevMarr, FemalePctDiv, TotalPctDiv, PersPerFam, PctFam2Par, PctKids2Par, PctYoungKids2Par, PctTeen2Par, PctWorkMomYoungKids, PctWorkMom, NumIlleg, PctIlleg, NumImmig, PctImmigRecent, PctImmigRec5, PctImmigRec8, PctImmigRec10, PctRecentImmig, PctRecImmig5, PctRecImmig8, PctRecImmig10, PctSpeakEnglOnly, PctNotSpeakEnglWell, PctLargHouseFam, PctLargHouseOccup, PersPerOccupHous, PersPerOwnOccHous, PersPerRentOccHous, PctPersOwnOccup, PctPersDenseHous, PctHousLess3BR, MedNumBR, HousVacant, PctHousOccup, PctHousOwnOcc, PctVacantBoarded, PctVacMore6Mos, MedYrHousBuilt, PctHousNoPhone, PctWOFullPlumb, OwnOccLowQuart, OwnOccMedVal, OwnOccHiQuart, RentLowQ, RentMedian, RentHighQ, MedRent, MedRentPctHousInc, MedOwnCostPctInc, MedOwnCostPctIncNoMtg, NumInShelters, NumStreet, PctForeignBorn, PctBornSameState, PctSameHouse85, PctSameCity85, PctSameState85, LandArea, PopDens, PctUsePubTrans, ViolentCrimesPerPop]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "print communities_matrix[communities_matrix.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12   \n",
       "1        0.00           0.16          0.12          0.74          0.45   \n",
       "2        0.00           0.42          0.49          0.56          0.17   \n",
       "3        0.04           0.77          1.00          0.08          0.12   \n",
       "4        0.01           0.55          0.02          0.95          0.09   \n",
       "5        0.02           0.28          0.06          0.54          1.00   \n",
       "6        0.01           0.39          0.00          0.98          0.06   \n",
       "7        0.01           0.74          0.03          0.46          0.20   \n",
       "8        0.03           0.34          0.20          0.84          0.02   \n",
       "9        0.01           0.40          0.06          0.87          0.30   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.17         0.34         0.47         0.29        0.32   \n",
       "1         0.07         0.26         0.59         0.35        0.27   \n",
       "2         0.04         0.39         0.47         0.28        0.32   \n",
       "3         0.10         0.51         0.50         0.34        0.21   \n",
       "4         0.05         0.38         0.38         0.23        0.36   \n",
       "5         0.25         0.31         0.48         0.27        0.37   \n",
       "6         0.02         0.30         0.37         0.23        0.60   \n",
       "7         1.00         0.52         0.55         0.36        0.35   \n",
       "8         0.00         0.38         0.45         0.28        0.48   \n",
       "9         0.03         0.90         0.82         0.80        0.39   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                 0.0            0.12              0.42   \n",
       "1         ...                 0.0            0.21              0.50   \n",
       "2         ...                 0.0            0.14              0.49   \n",
       "3         ...                 0.0            0.19              0.30   \n",
       "4         ...                 0.0            0.11              0.72   \n",
       "5         ...                 0.0            0.70              0.42   \n",
       "6         ...                 0.0            0.15              0.81   \n",
       "7         ...                 0.0            0.59              0.58   \n",
       "8         ...                 0.0            0.01              0.78   \n",
       "9         ...                 0.0            0.22              0.42   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.50           0.51            0.64      0.12     0.26   \n",
       "1            0.34           0.60            0.52      0.02     0.12   \n",
       "2            0.54           0.67            0.56      0.01     0.21   \n",
       "3            0.73           0.64            0.65      0.02     0.39   \n",
       "4            0.64           0.61            0.53      0.04     0.09   \n",
       "5            0.49           0.73            0.64      0.01     0.58   \n",
       "6            0.77           0.91            0.84      0.05     0.08   \n",
       "7            0.52           0.79            0.78      0.01     0.33   \n",
       "8            0.48           0.79            0.75      0.04     0.17   \n",
       "9            0.34           0.23            0.09      0.00     0.47   \n",
       "\n",
       "   PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.20                 0.20  \n",
       "1            0.45                 0.67  \n",
       "2            0.02                 0.43  \n",
       "3            0.28                 0.12  \n",
       "4            0.02                 0.03  \n",
       "5            0.10                 0.14  \n",
       "6            0.06                 0.03  \n",
       "7            0.00                 0.55  \n",
       "8            0.04                 0.53  \n",
       "9            0.11                 0.15  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.046228</td>\n",
       "      <td>0.232235</td>\n",
       "      <td>-0.301540</td>\n",
       "      <td>0.181526</td>\n",
       "      <td>0.156149</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.130264</td>\n",
       "      <td>0.075541</td>\n",
       "      <td>-0.101897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0.172637</td>\n",
       "      <td>-0.125008</td>\n",
       "      <td>-0.123584</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>0.713643</td>\n",
       "      <td>0.231838</td>\n",
       "      <td>0.270305</td>\n",
       "      <td>0.367160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdsize</th>\n",
       "      <td>-0.046228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066473</td>\n",
       "      <td>-0.236766</td>\n",
       "      <td>0.201858</td>\n",
       "      <td>0.468581</td>\n",
       "      <td>0.520523</td>\n",
       "      <td>0.367235</td>\n",
       "      <td>0.295154</td>\n",
       "      <td>-0.612600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043072</td>\n",
       "      <td>0.310962</td>\n",
       "      <td>-0.048983</td>\n",
       "      <td>-0.057625</td>\n",
       "      <td>-0.102883</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.015138</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.051637</td>\n",
       "      <td>-0.034934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racepctblack</th>\n",
       "      <td>0.232235</td>\n",
       "      <td>-0.066473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.793863</td>\n",
       "      <td>-0.105925</td>\n",
       "      <td>-0.065837</td>\n",
       "      <td>0.122485</td>\n",
       "      <td>0.154916</td>\n",
       "      <td>0.135043</td>\n",
       "      <td>0.051686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167916</td>\n",
       "      <td>-0.096966</td>\n",
       "      <td>0.091961</td>\n",
       "      <td>-0.047216</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.150503</td>\n",
       "      <td>0.096183</td>\n",
       "      <td>0.148176</td>\n",
       "      <td>0.632904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctWhite</th>\n",
       "      <td>-0.301540</td>\n",
       "      <td>-0.236766</td>\n",
       "      <td>-0.793863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.271379</td>\n",
       "      <td>-0.445371</td>\n",
       "      <td>-0.194137</td>\n",
       "      <td>-0.267920</td>\n",
       "      <td>-0.184470</td>\n",
       "      <td>0.137636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239464</td>\n",
       "      <td>-0.374424</td>\n",
       "      <td>0.115216</td>\n",
       "      <td>0.166519</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>-0.131802</td>\n",
       "      <td>-0.338501</td>\n",
       "      <td>-0.216444</td>\n",
       "      <td>-0.685631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctAsian</th>\n",
       "      <td>0.181526</td>\n",
       "      <td>0.201858</td>\n",
       "      <td>-0.105925</td>\n",
       "      <td>-0.271379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266598</td>\n",
       "      <td>-0.024988</td>\n",
       "      <td>0.100524</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-0.271802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169384</td>\n",
       "      <td>0.657352</td>\n",
       "      <td>-0.405063</td>\n",
       "      <td>-0.189265</td>\n",
       "      <td>-0.194646</td>\n",
       "      <td>-0.198114</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>0.389828</td>\n",
       "      <td>0.296805</td>\n",
       "      <td>0.037614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>racePctHisp</th>\n",
       "      <td>0.156149</td>\n",
       "      <td>0.468581</td>\n",
       "      <td>-0.065837</td>\n",
       "      <td>-0.445371</td>\n",
       "      <td>0.266598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145783</td>\n",
       "      <td>0.205720</td>\n",
       "      <td>0.086239</td>\n",
       "      <td>-0.227504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157672</td>\n",
       "      <td>0.684126</td>\n",
       "      <td>-0.261949</td>\n",
       "      <td>-0.165463</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.370002</td>\n",
       "      <td>0.078236</td>\n",
       "      <td>0.293065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t21</th>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.520523</td>\n",
       "      <td>0.122485</td>\n",
       "      <td>-0.194137</td>\n",
       "      <td>-0.024988</td>\n",
       "      <td>0.145783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822548</td>\n",
       "      <td>0.894606</td>\n",
       "      <td>-0.411083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024934</td>\n",
       "      <td>-0.068506</td>\n",
       "      <td>0.080249</td>\n",
       "      <td>-0.357267</td>\n",
       "      <td>-0.361372</td>\n",
       "      <td>-0.150600</td>\n",
       "      <td>0.025748</td>\n",
       "      <td>-0.095728</td>\n",
       "      <td>-0.173265</td>\n",
       "      <td>0.060479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct12t29</th>\n",
       "      <td>0.130264</td>\n",
       "      <td>0.367235</td>\n",
       "      <td>0.154916</td>\n",
       "      <td>-0.267920</td>\n",
       "      <td>0.100524</td>\n",
       "      <td>0.205720</td>\n",
       "      <td>0.822548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933727</td>\n",
       "      <td>-0.520506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068469</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.558953</td>\n",
       "      <td>-0.505845</td>\n",
       "      <td>-0.317513</td>\n",
       "      <td>0.062408</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>-0.023671</td>\n",
       "      <td>0.153362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct16t24</th>\n",
       "      <td>0.075541</td>\n",
       "      <td>0.295154</td>\n",
       "      <td>0.135043</td>\n",
       "      <td>-0.184470</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.086239</td>\n",
       "      <td>0.894606</td>\n",
       "      <td>0.933727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.322992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036995</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>-0.013581</td>\n",
       "      <td>-0.462830</td>\n",
       "      <td>-0.479017</td>\n",
       "      <td>-0.274456</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0.045874</td>\n",
       "      <td>-0.040520</td>\n",
       "      <td>0.099344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agePct65up</th>\n",
       "      <td>-0.101897</td>\n",
       "      <td>-0.612600</td>\n",
       "      <td>0.051686</td>\n",
       "      <td>0.137636</td>\n",
       "      <td>-0.271802</td>\n",
       "      <td>-0.227504</td>\n",
       "      <td>-0.411083</td>\n",
       "      <td>-0.520506</td>\n",
       "      <td>-0.322992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036585</td>\n",
       "      <td>-0.139621</td>\n",
       "      <td>0.149343</td>\n",
       "      <td>0.394105</td>\n",
       "      <td>0.372693</td>\n",
       "      <td>0.255469</td>\n",
       "      <td>-0.124169</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.067199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbUrban</th>\n",
       "      <td>0.993122</td>\n",
       "      <td>-0.047714</td>\n",
       "      <td>0.224839</td>\n",
       "      <td>-0.296160</td>\n",
       "      <td>0.200457</td>\n",
       "      <td>0.153819</td>\n",
       "      <td>-0.021343</td>\n",
       "      <td>0.112470</td>\n",
       "      <td>0.054485</td>\n",
       "      <td>-0.105883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>0.194946</td>\n",
       "      <td>-0.140007</td>\n",
       "      <td>-0.104999</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>-0.089475</td>\n",
       "      <td>0.693439</td>\n",
       "      <td>0.258044</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.362912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctUrban</th>\n",
       "      <td>0.239366</td>\n",
       "      <td>-0.016151</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>-0.054090</td>\n",
       "      <td>0.269037</td>\n",
       "      <td>0.037872</td>\n",
       "      <td>-0.240063</td>\n",
       "      <td>-0.090463</td>\n",
       "      <td>-0.139297</td>\n",
       "      <td>-0.110738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131550</td>\n",
       "      <td>0.292632</td>\n",
       "      <td>-0.232952</td>\n",
       "      <td>0.097254</td>\n",
       "      <td>0.070739</td>\n",
       "      <td>-0.074317</td>\n",
       "      <td>0.080914</td>\n",
       "      <td>0.330905</td>\n",
       "      <td>0.343409</td>\n",
       "      <td>0.082049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medIncome</th>\n",
       "      <td>-0.101853</td>\n",
       "      <td>0.209201</td>\n",
       "      <td>-0.359677</td>\n",
       "      <td>0.307763</td>\n",
       "      <td>0.362713</td>\n",
       "      <td>-0.140917</td>\n",
       "      <td>-0.296782</td>\n",
       "      <td>-0.343347</td>\n",
       "      <td>-0.327212</td>\n",
       "      <td>-0.289694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083965</td>\n",
       "      <td>0.227686</td>\n",
       "      <td>-0.244987</td>\n",
       "      <td>0.249582</td>\n",
       "      <td>-0.005568</td>\n",
       "      <td>-0.051464</td>\n",
       "      <td>-0.047549</td>\n",
       "      <td>-0.024034</td>\n",
       "      <td>0.250257</td>\n",
       "      <td>-0.424422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWWage</th>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.440187</td>\n",
       "      <td>-0.225541</td>\n",
       "      <td>0.115551</td>\n",
       "      <td>0.310472</td>\n",
       "      <td>0.019141</td>\n",
       "      <td>0.119956</td>\n",
       "      <td>0.259353</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>-0.838696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046725</td>\n",
       "      <td>0.147896</td>\n",
       "      <td>-0.201546</td>\n",
       "      <td>-0.187224</td>\n",
       "      <td>-0.301125</td>\n",
       "      <td>-0.241418</td>\n",
       "      <td>0.060993</td>\n",
       "      <td>-0.034848</td>\n",
       "      <td>0.084254</td>\n",
       "      <td>-0.305763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <td>-0.130655</td>\n",
       "      <td>0.182668</td>\n",
       "      <td>-0.153727</td>\n",
       "      <td>0.097415</td>\n",
       "      <td>-0.087539</td>\n",
       "      <td>0.082947</td>\n",
       "      <td>0.265490</td>\n",
       "      <td>0.124736</td>\n",
       "      <td>0.144942</td>\n",
       "      <td>-0.158798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085129</td>\n",
       "      <td>-0.129928</td>\n",
       "      <td>0.081407</td>\n",
       "      <td>-0.138527</td>\n",
       "      <td>-0.162278</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>-0.011216</td>\n",
       "      <td>-0.265205</td>\n",
       "      <td>-0.244865</td>\n",
       "      <td>-0.153123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWInvInc</th>\n",
       "      <td>-0.150987</td>\n",
       "      <td>-0.155420</td>\n",
       "      <td>-0.492630</td>\n",
       "      <td>0.595801</td>\n",
       "      <td>0.165982</td>\n",
       "      <td>-0.417612</td>\n",
       "      <td>-0.279115</td>\n",
       "      <td>-0.357636</td>\n",
       "      <td>-0.221821</td>\n",
       "      <td>0.076217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125109</td>\n",
       "      <td>-0.037754</td>\n",
       "      <td>-0.134692</td>\n",
       "      <td>0.255047</td>\n",
       "      <td>-0.053952</td>\n",
       "      <td>-0.074027</td>\n",
       "      <td>-0.073307</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>0.161068</td>\n",
       "      <td>-0.576499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWSocSec</th>\n",
       "      <td>-0.120134</td>\n",
       "      <td>-0.451298</td>\n",
       "      <td>0.110489</td>\n",
       "      <td>0.068435</td>\n",
       "      <td>-0.369429</td>\n",
       "      <td>-0.156953</td>\n",
       "      <td>-0.257966</td>\n",
       "      <td>-0.420773</td>\n",
       "      <td>-0.233191</td>\n",
       "      <td>0.941797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056437</td>\n",
       "      <td>-0.195784</td>\n",
       "      <td>0.282247</td>\n",
       "      <td>0.437809</td>\n",
       "      <td>0.434151</td>\n",
       "      <td>0.356144</td>\n",
       "      <td>-0.126963</td>\n",
       "      <td>-0.024207</td>\n",
       "      <td>-0.058103</td>\n",
       "      <td>0.118026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <td>0.177678</td>\n",
       "      <td>0.115870</td>\n",
       "      <td>0.443226</td>\n",
       "      <td>-0.588600</td>\n",
       "      <td>-0.058436</td>\n",
       "      <td>0.420799</td>\n",
       "      <td>0.213523</td>\n",
       "      <td>0.192829</td>\n",
       "      <td>0.151366</td>\n",
       "      <td>0.142203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166082</td>\n",
       "      <td>0.129229</td>\n",
       "      <td>0.204189</td>\n",
       "      <td>-0.053344</td>\n",
       "      <td>0.218824</td>\n",
       "      <td>0.210388</td>\n",
       "      <td>0.030730</td>\n",
       "      <td>0.197866</td>\n",
       "      <td>-0.015947</td>\n",
       "      <td>0.575327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pctWRetire</th>\n",
       "      <td>-0.093903</td>\n",
       "      <td>-0.324705</td>\n",
       "      <td>-0.072675</td>\n",
       "      <td>0.228683</td>\n",
       "      <td>-0.173983</td>\n",
       "      <td>-0.262015</td>\n",
       "      <td>-0.312080</td>\n",
       "      <td>-0.424440</td>\n",
       "      <td>-0.271478</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067948</td>\n",
       "      <td>-0.205031</td>\n",
       "      <td>0.094712</td>\n",
       "      <td>0.378977</td>\n",
       "      <td>0.260235</td>\n",
       "      <td>0.167277</td>\n",
       "      <td>-0.052642</td>\n",
       "      <td>-0.087981</td>\n",
       "      <td>-0.040556</td>\n",
       "      <td>-0.098441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medFamInc</th>\n",
       "      <td>-0.105608</td>\n",
       "      <td>0.111162</td>\n",
       "      <td>-0.358967</td>\n",
       "      <td>0.342475</td>\n",
       "      <td>0.353201</td>\n",
       "      <td>-0.205209</td>\n",
       "      <td>-0.266184</td>\n",
       "      <td>-0.308424</td>\n",
       "      <td>-0.259695</td>\n",
       "      <td>-0.224684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086261</td>\n",
       "      <td>0.198791</td>\n",
       "      <td>-0.238126</td>\n",
       "      <td>0.229966</td>\n",
       "      <td>-0.040818</td>\n",
       "      <td>-0.068901</td>\n",
       "      <td>-0.058154</td>\n",
       "      <td>-0.017385</td>\n",
       "      <td>0.275162</td>\n",
       "      <td>-0.439313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perCapInc</th>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.130979</td>\n",
       "      <td>-0.286244</td>\n",
       "      <td>0.314546</td>\n",
       "      <td>0.318778</td>\n",
       "      <td>-0.242352</td>\n",
       "      <td>-0.405084</td>\n",
       "      <td>-0.414344</td>\n",
       "      <td>-0.342344</td>\n",
       "      <td>-0.030757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028261</td>\n",
       "      <td>0.189381</td>\n",
       "      <td>-0.296931</td>\n",
       "      <td>0.216965</td>\n",
       "      <td>-0.023194</td>\n",
       "      <td>-0.119385</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.307742</td>\n",
       "      <td>-0.352170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitePerCap</th>\n",
       "      <td>0.037007</td>\n",
       "      <td>-0.131748</td>\n",
       "      <td>-0.102367</td>\n",
       "      <td>0.123190</td>\n",
       "      <td>0.355572</td>\n",
       "      <td>-0.200691</td>\n",
       "      <td>-0.384188</td>\n",
       "      <td>-0.378667</td>\n",
       "      <td>-0.315009</td>\n",
       "      <td>-0.033370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042606</td>\n",
       "      <td>0.231715</td>\n",
       "      <td>-0.314973</td>\n",
       "      <td>0.184989</td>\n",
       "      <td>-0.025422</td>\n",
       "      <td>-0.136007</td>\n",
       "      <td>0.020059</td>\n",
       "      <td>0.064175</td>\n",
       "      <td>0.360911</td>\n",
       "      <td>-0.209280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blackPerCap</th>\n",
       "      <td>-0.059780</td>\n",
       "      <td>0.042306</td>\n",
       "      <td>-0.254073</td>\n",
       "      <td>0.186967</td>\n",
       "      <td>0.299927</td>\n",
       "      <td>-0.064154</td>\n",
       "      <td>-0.283802</td>\n",
       "      <td>-0.260035</td>\n",
       "      <td>-0.262010</td>\n",
       "      <td>-0.170252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044414</td>\n",
       "      <td>0.226769</td>\n",
       "      <td>-0.183917</td>\n",
       "      <td>0.183147</td>\n",
       "      <td>0.022653</td>\n",
       "      <td>-0.030075</td>\n",
       "      <td>-0.058515</td>\n",
       "      <td>0.074220</td>\n",
       "      <td>0.226187</td>\n",
       "      <td>-0.275452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indianPerCap</th>\n",
       "      <td>-0.017378</td>\n",
       "      <td>-0.008043</td>\n",
       "      <td>-0.047456</td>\n",
       "      <td>0.039055</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>-0.009973</td>\n",
       "      <td>-0.157383</td>\n",
       "      <td>-0.149951</td>\n",
       "      <td>-0.151153</td>\n",
       "      <td>-0.050408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006817</td>\n",
       "      <td>0.103310</td>\n",
       "      <td>-0.126121</td>\n",
       "      <td>0.047506</td>\n",
       "      <td>-0.014866</td>\n",
       "      <td>-0.025912</td>\n",
       "      <td>-0.018141</td>\n",
       "      <td>0.040204</td>\n",
       "      <td>0.091772</td>\n",
       "      <td>-0.090880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AsianPerCap</th>\n",
       "      <td>-0.081000</td>\n",
       "      <td>-0.055760</td>\n",
       "      <td>-0.116263</td>\n",
       "      <td>0.145649</td>\n",
       "      <td>0.095895</td>\n",
       "      <td>-0.113946</td>\n",
       "      <td>-0.265317</td>\n",
       "      <td>-0.325119</td>\n",
       "      <td>-0.275544</td>\n",
       "      <td>0.049929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041541</td>\n",
       "      <td>0.080861</td>\n",
       "      <td>-0.058688</td>\n",
       "      <td>0.231919</td>\n",
       "      <td>0.129662</td>\n",
       "      <td>0.069164</td>\n",
       "      <td>-0.041184</td>\n",
       "      <td>-0.025089</td>\n",
       "      <td>0.124098</td>\n",
       "      <td>-0.155590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OtherPerCap</th>\n",
       "      <td>-0.031002</td>\n",
       "      <td>0.016720</td>\n",
       "      <td>-0.106167</td>\n",
       "      <td>0.104998</td>\n",
       "      <td>0.192715</td>\n",
       "      <td>-0.096380</td>\n",
       "      <td>-0.174010</td>\n",
       "      <td>-0.151272</td>\n",
       "      <td>-0.161568</td>\n",
       "      <td>-0.112777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041669</td>\n",
       "      <td>0.116160</td>\n",
       "      <td>-0.145983</td>\n",
       "      <td>0.086661</td>\n",
       "      <td>-0.028959</td>\n",
       "      <td>-0.047641</td>\n",
       "      <td>-0.010158</td>\n",
       "      <td>0.029342</td>\n",
       "      <td>0.146859</td>\n",
       "      <td>-0.126345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HispPerCap</th>\n",
       "      <td>-0.082906</td>\n",
       "      <td>-0.084791</td>\n",
       "      <td>-0.154366</td>\n",
       "      <td>0.214853</td>\n",
       "      <td>0.199602</td>\n",
       "      <td>-0.239855</td>\n",
       "      <td>-0.311375</td>\n",
       "      <td>-0.321404</td>\n",
       "      <td>-0.279327</td>\n",
       "      <td>-0.030228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073177</td>\n",
       "      <td>0.086312</td>\n",
       "      <td>-0.153813</td>\n",
       "      <td>0.243155</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>-0.030592</td>\n",
       "      <td>-0.041458</td>\n",
       "      <td>-0.013475</td>\n",
       "      <td>0.215542</td>\n",
       "      <td>-0.244639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumUnderPov</th>\n",
       "      <td>0.947613</td>\n",
       "      <td>-0.030152</td>\n",
       "      <td>0.323340</td>\n",
       "      <td>-0.376910</td>\n",
       "      <td>0.089707</td>\n",
       "      <td>0.196445</td>\n",
       "      <td>0.086405</td>\n",
       "      <td>0.177731</td>\n",
       "      <td>0.135676</td>\n",
       "      <td>-0.062347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641195</td>\n",
       "      <td>0.135856</td>\n",
       "      <td>-0.055761</td>\n",
       "      <td>-0.116689</td>\n",
       "      <td>0.033049</td>\n",
       "      <td>-0.046699</td>\n",
       "      <td>0.649900</td>\n",
       "      <td>0.227736</td>\n",
       "      <td>0.258572</td>\n",
       "      <td>0.447581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <td>0.162597</td>\n",
       "      <td>0.055782</td>\n",
       "      <td>0.488371</td>\n",
       "      <td>-0.540938</td>\n",
       "      <td>-0.173054</td>\n",
       "      <td>0.315825</td>\n",
       "      <td>0.500819</td>\n",
       "      <td>0.455564</td>\n",
       "      <td>0.472267</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132607</td>\n",
       "      <td>-0.026376</td>\n",
       "      <td>0.152630</td>\n",
       "      <td>-0.264225</td>\n",
       "      <td>-0.052178</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.066514</td>\n",
       "      <td>0.065777</td>\n",
       "      <td>-0.108570</td>\n",
       "      <td>0.522670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <td>0.036873</td>\n",
       "      <td>0.172472</td>\n",
       "      <td>0.286177</td>\n",
       "      <td>-0.470304</td>\n",
       "      <td>-0.161614</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.174316</td>\n",
       "      <td>0.147494</td>\n",
       "      <td>0.111562</td>\n",
       "      <td>0.196977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073074</td>\n",
       "      <td>0.232059</td>\n",
       "      <td>0.230260</td>\n",
       "      <td>0.092012</td>\n",
       "      <td>0.299533</td>\n",
       "      <td>0.272570</td>\n",
       "      <td>-0.042898</td>\n",
       "      <td>0.181251</td>\n",
       "      <td>-0.080374</td>\n",
       "      <td>0.411228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedNumBR</th>\n",
       "      <td>-0.205210</td>\n",
       "      <td>0.221812</td>\n",
       "      <td>-0.147140</td>\n",
       "      <td>0.281104</td>\n",
       "      <td>-0.084585</td>\n",
       "      <td>-0.294034</td>\n",
       "      <td>-0.079190</td>\n",
       "      <td>-0.298290</td>\n",
       "      <td>-0.267915</td>\n",
       "      <td>-0.163774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187825</td>\n",
       "      <td>-0.267385</td>\n",
       "      <td>0.183813</td>\n",
       "      <td>0.311718</td>\n",
       "      <td>0.137198</td>\n",
       "      <td>0.158384</td>\n",
       "      <td>-0.055292</td>\n",
       "      <td>-0.311522</td>\n",
       "      <td>-0.109614</td>\n",
       "      <td>-0.357420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HousVacant</th>\n",
       "      <td>0.896325</td>\n",
       "      <td>-0.175653</td>\n",
       "      <td>0.280897</td>\n",
       "      <td>-0.281461</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>0.104456</td>\n",
       "      <td>-0.047199</td>\n",
       "      <td>0.066072</td>\n",
       "      <td>0.035427</td>\n",
       "      <td>0.038799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595498</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>-0.165341</td>\n",
       "      <td>-0.151376</td>\n",
       "      <td>-0.034030</td>\n",
       "      <td>-0.142461</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.150503</td>\n",
       "      <td>0.215275</td>\n",
       "      <td>0.421396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOccup</th>\n",
       "      <td>-0.090066</td>\n",
       "      <td>0.229987</td>\n",
       "      <td>-0.251939</td>\n",
       "      <td>0.177254</td>\n",
       "      <td>0.248663</td>\n",
       "      <td>-0.080283</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>-0.277634</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079233</td>\n",
       "      <td>0.105116</td>\n",
       "      <td>0.170854</td>\n",
       "      <td>0.228462</td>\n",
       "      <td>0.156613</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-0.177257</td>\n",
       "      <td>0.140246</td>\n",
       "      <td>0.117863</td>\n",
       "      <td>-0.319112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <td>-0.253141</td>\n",
       "      <td>0.192789</td>\n",
       "      <td>-0.340068</td>\n",
       "      <td>0.441429</td>\n",
       "      <td>-0.109821</td>\n",
       "      <td>-0.261729</td>\n",
       "      <td>-0.260620</td>\n",
       "      <td>-0.587321</td>\n",
       "      <td>-0.487895</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230288</td>\n",
       "      <td>-0.226424</td>\n",
       "      <td>0.125130</td>\n",
       "      <td>0.514294</td>\n",
       "      <td>0.267242</td>\n",
       "      <td>0.278335</td>\n",
       "      <td>-0.041544</td>\n",
       "      <td>-0.448368</td>\n",
       "      <td>-0.196144</td>\n",
       "      <td>-0.470683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <td>0.326240</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.473352</td>\n",
       "      <td>-0.451001</td>\n",
       "      <td>-0.136218</td>\n",
       "      <td>0.164274</td>\n",
       "      <td>0.121929</td>\n",
       "      <td>0.099811</td>\n",
       "      <td>0.065746</td>\n",
       "      <td>0.024233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219195</td>\n",
       "      <td>-0.047458</td>\n",
       "      <td>0.177153</td>\n",
       "      <td>0.112447</td>\n",
       "      <td>0.247518</td>\n",
       "      <td>0.188278</td>\n",
       "      <td>0.220112</td>\n",
       "      <td>0.128895</td>\n",
       "      <td>0.138658</td>\n",
       "      <td>0.482853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <td>-0.085246</td>\n",
       "      <td>-0.036688</td>\n",
       "      <td>0.167132</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>-0.389248</td>\n",
       "      <td>-0.157279</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>-0.148961</td>\n",
       "      <td>-0.076210</td>\n",
       "      <td>0.256085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072178</td>\n",
       "      <td>-0.318676</td>\n",
       "      <td>0.386178</td>\n",
       "      <td>0.394716</td>\n",
       "      <td>0.326764</td>\n",
       "      <td>0.315617</td>\n",
       "      <td>0.028985</td>\n",
       "      <td>-0.196966</td>\n",
       "      <td>-0.036737</td>\n",
       "      <td>0.021314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <td>-0.056744</td>\n",
       "      <td>0.253791</td>\n",
       "      <td>-0.085518</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>0.074298</td>\n",
       "      <td>0.091944</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>-0.421088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049484</td>\n",
       "      <td>-0.032298</td>\n",
       "      <td>-0.352609</td>\n",
       "      <td>-0.495242</td>\n",
       "      <td>-0.483788</td>\n",
       "      <td>-0.363762</td>\n",
       "      <td>0.137922</td>\n",
       "      <td>-0.410634</td>\n",
       "      <td>-0.391554</td>\n",
       "      <td>-0.110010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <td>0.061649</td>\n",
       "      <td>-0.007665</td>\n",
       "      <td>0.484772</td>\n",
       "      <td>-0.480665</td>\n",
       "      <td>-0.304801</td>\n",
       "      <td>0.274521</td>\n",
       "      <td>0.279850</td>\n",
       "      <td>0.220738</td>\n",
       "      <td>0.201489</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069642</td>\n",
       "      <td>-0.146178</td>\n",
       "      <td>0.196235</td>\n",
       "      <td>-0.152454</td>\n",
       "      <td>0.069812</td>\n",
       "      <td>0.076350</td>\n",
       "      <td>0.049198</td>\n",
       "      <td>-0.059114</td>\n",
       "      <td>-0.202486</td>\n",
       "      <td>0.488386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <td>0.108330</td>\n",
       "      <td>0.143837</td>\n",
       "      <td>0.301573</td>\n",
       "      <td>-0.418241</td>\n",
       "      <td>-0.080564</td>\n",
       "      <td>0.369984</td>\n",
       "      <td>0.173942</td>\n",
       "      <td>0.150435</td>\n",
       "      <td>0.115675</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146095</td>\n",
       "      <td>0.161381</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.153390</td>\n",
       "      <td>0.119830</td>\n",
       "      <td>0.080075</td>\n",
       "      <td>0.163849</td>\n",
       "      <td>0.054767</td>\n",
       "      <td>0.364682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <td>-0.012270</td>\n",
       "      <td>0.134387</td>\n",
       "      <td>-0.287078</td>\n",
       "      <td>0.090304</td>\n",
       "      <td>0.584750</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>-0.258728</td>\n",
       "      <td>-0.178608</td>\n",
       "      <td>-0.166238</td>\n",
       "      <td>-0.158990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038102</td>\n",
       "      <td>0.543471</td>\n",
       "      <td>-0.361738</td>\n",
       "      <td>0.129316</td>\n",
       "      <td>-0.031608</td>\n",
       "      <td>-0.090975</td>\n",
       "      <td>-0.086487</td>\n",
       "      <td>0.278326</td>\n",
       "      <td>0.391054</td>\n",
       "      <td>-0.210610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.123546</td>\n",
       "      <td>-0.269074</td>\n",
       "      <td>0.072110</td>\n",
       "      <td>0.587474</td>\n",
       "      <td>0.085324</td>\n",
       "      <td>-0.249730</td>\n",
       "      <td>-0.178391</td>\n",
       "      <td>-0.158829</td>\n",
       "      <td>-0.149636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>0.546922</td>\n",
       "      <td>-0.375572</td>\n",
       "      <td>0.110653</td>\n",
       "      <td>-0.045764</td>\n",
       "      <td>-0.108123</td>\n",
       "      <td>-0.074714</td>\n",
       "      <td>0.275894</td>\n",
       "      <td>0.394247</td>\n",
       "      <td>-0.190776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <td>0.018459</td>\n",
       "      <td>0.100238</td>\n",
       "      <td>-0.245531</td>\n",
       "      <td>0.060425</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>0.076351</td>\n",
       "      <td>-0.242267</td>\n",
       "      <td>-0.184413</td>\n",
       "      <td>-0.152545</td>\n",
       "      <td>-0.128573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076572</td>\n",
       "      <td>0.532702</td>\n",
       "      <td>-0.389806</td>\n",
       "      <td>0.092198</td>\n",
       "      <td>-0.061083</td>\n",
       "      <td>-0.131252</td>\n",
       "      <td>-0.056469</td>\n",
       "      <td>0.259238</td>\n",
       "      <td>0.391711</td>\n",
       "      <td>-0.172164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentLowQ</th>\n",
       "      <td>-0.006718</td>\n",
       "      <td>0.149730</td>\n",
       "      <td>-0.319752</td>\n",
       "      <td>0.126575</td>\n",
       "      <td>0.568032</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>-0.297032</td>\n",
       "      <td>-0.159619</td>\n",
       "      <td>-0.197852</td>\n",
       "      <td>-0.260477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.497059</td>\n",
       "      <td>-0.452058</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>-0.144318</td>\n",
       "      <td>-0.179558</td>\n",
       "      <td>-0.059525</td>\n",
       "      <td>0.251077</td>\n",
       "      <td>0.325284</td>\n",
       "      <td>-0.252032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentMedian</th>\n",
       "      <td>-0.010063</td>\n",
       "      <td>0.167679</td>\n",
       "      <td>-0.303350</td>\n",
       "      <td>0.125313</td>\n",
       "      <td>0.546945</td>\n",
       "      <td>0.055650</td>\n",
       "      <td>-0.299337</td>\n",
       "      <td>-0.194770</td>\n",
       "      <td>-0.207516</td>\n",
       "      <td>-0.225103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>0.499604</td>\n",
       "      <td>-0.420259</td>\n",
       "      <td>0.082493</td>\n",
       "      <td>-0.097129</td>\n",
       "      <td>-0.143384</td>\n",
       "      <td>-0.054105</td>\n",
       "      <td>0.231813</td>\n",
       "      <td>0.368063</td>\n",
       "      <td>-0.240654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RentHighQ</th>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.179479</td>\n",
       "      <td>-0.292184</td>\n",
       "      <td>0.119562</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>0.059832</td>\n",
       "      <td>-0.287044</td>\n",
       "      <td>-0.195122</td>\n",
       "      <td>-0.197996</td>\n",
       "      <td>-0.218842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>0.504381</td>\n",
       "      <td>-0.420564</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>-0.101541</td>\n",
       "      <td>-0.149243</td>\n",
       "      <td>-0.040882</td>\n",
       "      <td>0.234664</td>\n",
       "      <td>0.387958</td>\n",
       "      <td>-0.232405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRent</th>\n",
       "      <td>-0.024876</td>\n",
       "      <td>0.181018</td>\n",
       "      <td>-0.278048</td>\n",
       "      <td>0.124712</td>\n",
       "      <td>0.509870</td>\n",
       "      <td>0.028163</td>\n",
       "      <td>-0.307269</td>\n",
       "      <td>-0.224061</td>\n",
       "      <td>-0.234780</td>\n",
       "      <td>-0.225534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.459958</td>\n",
       "      <td>-0.399881</td>\n",
       "      <td>0.104751</td>\n",
       "      <td>-0.086725</td>\n",
       "      <td>-0.130475</td>\n",
       "      <td>-0.048723</td>\n",
       "      <td>0.187567</td>\n",
       "      <td>0.338039</td>\n",
       "      <td>-0.239985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <td>0.130543</td>\n",
       "      <td>0.130613</td>\n",
       "      <td>0.191661</td>\n",
       "      <td>-0.339442</td>\n",
       "      <td>0.178857</td>\n",
       "      <td>0.287340</td>\n",
       "      <td>0.273049</td>\n",
       "      <td>0.275221</td>\n",
       "      <td>0.337411</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128316</td>\n",
       "      <td>0.301422</td>\n",
       "      <td>-0.220473</td>\n",
       "      <td>-0.251303</td>\n",
       "      <td>-0.196164</td>\n",
       "      <td>-0.096873</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.102031</td>\n",
       "      <td>0.325091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <td>0.083208</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>-0.070098</td>\n",
       "      <td>-0.173558</td>\n",
       "      <td>0.398443</td>\n",
       "      <td>0.336924</td>\n",
       "      <td>-0.171145</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>-0.098937</td>\n",
       "      <td>-0.215051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127441</td>\n",
       "      <td>0.560820</td>\n",
       "      <td>-0.453341</td>\n",
       "      <td>-0.182908</td>\n",
       "      <td>-0.198099</td>\n",
       "      <td>-0.216482</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>0.299438</td>\n",
       "      <td>0.254961</td>\n",
       "      <td>0.063846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <td>-0.037735</td>\n",
       "      <td>-0.096058</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>-0.057446</td>\n",
       "      <td>-0.228924</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>-0.121343</td>\n",
       "      <td>-0.089328</td>\n",
       "      <td>-0.078579</td>\n",
       "      <td>0.203016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038695</td>\n",
       "      <td>-0.029792</td>\n",
       "      <td>0.195751</td>\n",
       "      <td>0.345228</td>\n",
       "      <td>0.224752</td>\n",
       "      <td>0.186936</td>\n",
       "      <td>-0.028060</td>\n",
       "      <td>0.128711</td>\n",
       "      <td>0.313671</td>\n",
       "      <td>0.053841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInShelters</th>\n",
       "      <td>0.821236</td>\n",
       "      <td>-0.082245</td>\n",
       "      <td>0.230360</td>\n",
       "      <td>-0.278398</td>\n",
       "      <td>0.131252</td>\n",
       "      <td>0.113962</td>\n",
       "      <td>-0.005874</td>\n",
       "      <td>0.100686</td>\n",
       "      <td>0.068004</td>\n",
       "      <td>-0.032102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718986</td>\n",
       "      <td>0.140463</td>\n",
       "      <td>-0.091270</td>\n",
       "      <td>-0.081306</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>-0.065202</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.243914</td>\n",
       "      <td>0.332407</td>\n",
       "      <td>0.375757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumStreet</th>\n",
       "      <td>0.651786</td>\n",
       "      <td>-0.043072</td>\n",
       "      <td>0.167916</td>\n",
       "      <td>-0.239464</td>\n",
       "      <td>0.169384</td>\n",
       "      <td>0.157672</td>\n",
       "      <td>-0.024934</td>\n",
       "      <td>0.068469</td>\n",
       "      <td>0.036995</td>\n",
       "      <td>-0.036585</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203561</td>\n",
       "      <td>-0.148715</td>\n",
       "      <td>-0.104463</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>-0.079357</td>\n",
       "      <td>0.425937</td>\n",
       "      <td>0.238854</td>\n",
       "      <td>0.239004</td>\n",
       "      <td>0.340277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <td>0.172637</td>\n",
       "      <td>0.310962</td>\n",
       "      <td>-0.096966</td>\n",
       "      <td>-0.374424</td>\n",
       "      <td>0.657352</td>\n",
       "      <td>0.684126</td>\n",
       "      <td>-0.068506</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>-0.139621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.495517</td>\n",
       "      <td>-0.072741</td>\n",
       "      <td>-0.023074</td>\n",
       "      <td>-0.137674</td>\n",
       "      <td>-0.048959</td>\n",
       "      <td>0.614694</td>\n",
       "      <td>0.401597</td>\n",
       "      <td>0.194414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctBornSameState</th>\n",
       "      <td>-0.125008</td>\n",
       "      <td>-0.048983</td>\n",
       "      <td>0.091961</td>\n",
       "      <td>0.115216</td>\n",
       "      <td>-0.405063</td>\n",
       "      <td>-0.261949</td>\n",
       "      <td>0.080249</td>\n",
       "      <td>-0.047189</td>\n",
       "      <td>-0.013581</td>\n",
       "      <td>0.149343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148715</td>\n",
       "      <td>-0.495517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.473455</td>\n",
       "      <td>0.512720</td>\n",
       "      <td>0.761715</td>\n",
       "      <td>-0.069166</td>\n",
       "      <td>-0.221114</td>\n",
       "      <td>-0.175249</td>\n",
       "      <td>-0.077164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <td>-0.123584</td>\n",
       "      <td>-0.057625</td>\n",
       "      <td>-0.047216</td>\n",
       "      <td>0.166519</td>\n",
       "      <td>-0.189265</td>\n",
       "      <td>-0.165463</td>\n",
       "      <td>-0.357267</td>\n",
       "      <td>-0.558953</td>\n",
       "      <td>-0.462830</td>\n",
       "      <td>0.394105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104463</td>\n",
       "      <td>-0.072741</td>\n",
       "      <td>0.473455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803016</td>\n",
       "      <td>0.670899</td>\n",
       "      <td>-0.116822</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.192641</td>\n",
       "      <td>-0.155405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameCity85</th>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.102883</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>-0.194646</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>-0.361372</td>\n",
       "      <td>-0.505845</td>\n",
       "      <td>-0.479017</td>\n",
       "      <td>0.372693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>-0.023074</td>\n",
       "      <td>0.512720</td>\n",
       "      <td>0.803016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>-0.062889</td>\n",
       "      <td>0.118405</td>\n",
       "      <td>0.081535</td>\n",
       "      <td>0.075595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctSameState85</th>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>-0.198114</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>-0.150600</td>\n",
       "      <td>-0.317513</td>\n",
       "      <td>-0.274456</td>\n",
       "      <td>0.255469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079357</td>\n",
       "      <td>-0.137674</td>\n",
       "      <td>0.761715</td>\n",
       "      <td>0.670899</td>\n",
       "      <td>0.741996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.104345</td>\n",
       "      <td>-0.012001</td>\n",
       "      <td>-0.042284</td>\n",
       "      <td>-0.019450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandArea</th>\n",
       "      <td>0.713643</td>\n",
       "      <td>-0.015138</td>\n",
       "      <td>0.150503</td>\n",
       "      <td>-0.131802</td>\n",
       "      <td>-0.001164</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.025748</td>\n",
       "      <td>0.062408</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>-0.124169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425937</td>\n",
       "      <td>-0.048959</td>\n",
       "      <td>-0.069166</td>\n",
       "      <td>-0.116822</td>\n",
       "      <td>-0.062889</td>\n",
       "      <td>-0.104345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>0.196799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PopDens</th>\n",
       "      <td>0.231838</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>0.096183</td>\n",
       "      <td>-0.338501</td>\n",
       "      <td>0.389828</td>\n",
       "      <td>0.370002</td>\n",
       "      <td>-0.095728</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.045874</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238854</td>\n",
       "      <td>0.614694</td>\n",
       "      <td>-0.221114</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.118405</td>\n",
       "      <td>-0.012001</td>\n",
       "      <td>-0.170936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>0.281402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <td>0.270305</td>\n",
       "      <td>-0.051637</td>\n",
       "      <td>0.148176</td>\n",
       "      <td>-0.216444</td>\n",
       "      <td>0.296805</td>\n",
       "      <td>0.078236</td>\n",
       "      <td>-0.173265</td>\n",
       "      <td>-0.023671</td>\n",
       "      <td>-0.040520</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239004</td>\n",
       "      <td>0.401597</td>\n",
       "      <td>-0.175249</td>\n",
       "      <td>0.192641</td>\n",
       "      <td>0.081535</td>\n",
       "      <td>-0.042284</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <td>0.367160</td>\n",
       "      <td>-0.034934</td>\n",
       "      <td>0.632904</td>\n",
       "      <td>-0.685631</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.293065</td>\n",
       "      <td>0.060479</td>\n",
       "      <td>0.153362</td>\n",
       "      <td>0.099344</td>\n",
       "      <td>0.067199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340277</td>\n",
       "      <td>0.194414</td>\n",
       "      <td>-0.077164</td>\n",
       "      <td>-0.155405</td>\n",
       "      <td>0.075595</td>\n",
       "      <td>-0.019450</td>\n",
       "      <td>0.196799</td>\n",
       "      <td>0.281402</td>\n",
       "      <td>0.153830</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       population  householdsize  racepctblack  racePctWhite  \\\n",
       "population               1.000000      -0.046228      0.232235     -0.301540   \n",
       "householdsize           -0.046228       1.000000     -0.066473     -0.236766   \n",
       "racepctblack             0.232235      -0.066473      1.000000     -0.793863   \n",
       "racePctWhite            -0.301540      -0.236766     -0.793863      1.000000   \n",
       "racePctAsian             0.181526       0.201858     -0.105925     -0.271379   \n",
       "racePctHisp              0.156149       0.468581     -0.065837     -0.445371   \n",
       "agePct12t21              0.006383       0.520523      0.122485     -0.194137   \n",
       "agePct12t29              0.130264       0.367235      0.154916     -0.267920   \n",
       "agePct16t24              0.075541       0.295154      0.135043     -0.184470   \n",
       "agePct65up              -0.101897      -0.612600      0.051686      0.137636   \n",
       "numbUrban                0.993122      -0.047714      0.224839     -0.296160   \n",
       "pctUrban                 0.239366      -0.016151      0.001216     -0.054090   \n",
       "medIncome               -0.101853       0.209201     -0.359677      0.307763   \n",
       "pctWWage                 0.004257       0.440187     -0.225541      0.115551   \n",
       "pctWFarmSelf            -0.130655       0.182668     -0.153727      0.097415   \n",
       "pctWInvInc              -0.150987      -0.155420     -0.492630      0.595801   \n",
       "pctWSocSec              -0.120134      -0.451298      0.110489      0.068435   \n",
       "pctWPubAsst              0.177678       0.115870      0.443226     -0.588600   \n",
       "pctWRetire              -0.093903      -0.324705     -0.072675      0.228683   \n",
       "medFamInc               -0.105608       0.111162     -0.358967      0.342475   \n",
       "perCapInc               -0.055801      -0.130979     -0.286244      0.314546   \n",
       "whitePerCap              0.037007      -0.131748     -0.102367      0.123190   \n",
       "blackPerCap             -0.059780       0.042306     -0.254073      0.186967   \n",
       "indianPerCap            -0.017378      -0.008043     -0.047456      0.039055   \n",
       "AsianPerCap             -0.081000      -0.055760     -0.116263      0.145649   \n",
       "OtherPerCap             -0.031002       0.016720     -0.106167      0.104998   \n",
       "HispPerCap              -0.082906      -0.084791     -0.154366      0.214853   \n",
       "NumUnderPov              0.947613      -0.030152      0.323340     -0.376910   \n",
       "PctPopUnderPov           0.162597       0.055782      0.488371     -0.540938   \n",
       "PctLess9thGrade          0.036873       0.172472      0.286177     -0.470304   \n",
       "...                           ...            ...           ...           ...   \n",
       "MedNumBR                -0.205210       0.221812     -0.147140      0.281104   \n",
       "HousVacant               0.896325      -0.175653      0.280897     -0.281461   \n",
       "PctHousOccup            -0.090066       0.229987     -0.251939      0.177254   \n",
       "PctHousOwnOcc           -0.253141       0.192789     -0.340068      0.441429   \n",
       "PctVacantBoarded         0.326240       0.051620      0.473352     -0.451001   \n",
       "PctVacMore6Mos          -0.085246      -0.036688      0.167132      0.008710   \n",
       "MedYrHousBuilt          -0.056744       0.253791     -0.085518      0.016857   \n",
       "PctHousNoPhone           0.061649      -0.007665      0.484772     -0.480665   \n",
       "PctWOFullPlumb           0.108330       0.143837      0.301573     -0.418241   \n",
       "OwnOccLowQuart          -0.012270       0.134387     -0.287078      0.090304   \n",
       "OwnOccMedVal             0.000559       0.123546     -0.269074      0.072110   \n",
       "OwnOccHiQuart            0.018459       0.100238     -0.245531      0.060425   \n",
       "RentLowQ                -0.006718       0.149730     -0.319752      0.126575   \n",
       "RentMedian              -0.010063       0.167679     -0.303350      0.125313   \n",
       "RentHighQ                0.003874       0.179479     -0.292184      0.119562   \n",
       "MedRent                 -0.024876       0.181018     -0.278048      0.124712   \n",
       "MedRentPctHousInc        0.130543       0.130613      0.191661     -0.339442   \n",
       "MedOwnCostPctInc         0.083208       0.247995     -0.070098     -0.173558   \n",
       "MedOwnCostPctIncNoMtg   -0.037735      -0.096058      0.218641     -0.057446   \n",
       "NumInShelters            0.821236      -0.082245      0.230360     -0.278398   \n",
       "NumStreet                0.651786      -0.043072      0.167916     -0.239464   \n",
       "PctForeignBorn           0.172637       0.310962     -0.096966     -0.374424   \n",
       "PctBornSameState        -0.125008      -0.048983      0.091961      0.115216   \n",
       "PctSameHouse85          -0.123584      -0.057625     -0.047216      0.166519   \n",
       "PctSameCity85            0.001761      -0.102883      0.054900     -0.018589   \n",
       "PctSameState85          -0.089559      -0.003125     -0.003852      0.033114   \n",
       "LandArea                 0.713643      -0.015138      0.150503     -0.131802   \n",
       "PopDens                  0.231838      -0.004214      0.096183     -0.338501   \n",
       "PctUsePubTrans           0.270305      -0.051637      0.148176     -0.216444   \n",
       "ViolentCrimesPerPop      0.367160      -0.034934      0.632904     -0.685631   \n",
       "\n",
       "                       racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "population                 0.181526     0.156149     0.006383     0.130264   \n",
       "householdsize              0.201858     0.468581     0.520523     0.367235   \n",
       "racepctblack              -0.105925    -0.065837     0.122485     0.154916   \n",
       "racePctWhite              -0.271379    -0.445371    -0.194137    -0.267920   \n",
       "racePctAsian               1.000000     0.266598    -0.024988     0.100524   \n",
       "racePctHisp                0.266598     1.000000     0.145783     0.205720   \n",
       "agePct12t21               -0.024988     0.145783     1.000000     0.822548   \n",
       "agePct12t29                0.100524     0.205720     0.822548     1.000000   \n",
       "agePct16t24                0.052632     0.086239     0.894606     0.933727   \n",
       "agePct65up                -0.271802    -0.227504    -0.411083    -0.520506   \n",
       "numbUrban                  0.200457     0.153819    -0.021343     0.112470   \n",
       "pctUrban                   0.269037     0.037872    -0.240063    -0.090463   \n",
       "medIncome                  0.362713    -0.140917    -0.296782    -0.343347   \n",
       "pctWWage                   0.310472     0.019141     0.119956     0.259353   \n",
       "pctWFarmSelf              -0.087539     0.082947     0.265490     0.124736   \n",
       "pctWInvInc                 0.165982    -0.417612    -0.279115    -0.357636   \n",
       "pctWSocSec                -0.369429    -0.156953    -0.257966    -0.420773   \n",
       "pctWPubAsst               -0.058436     0.420799     0.213523     0.192829   \n",
       "pctWRetire                -0.173983    -0.262015    -0.312080    -0.424440   \n",
       "medFamInc                  0.353201    -0.205209    -0.266184    -0.308424   \n",
       "perCapInc                  0.318778    -0.242352    -0.405084    -0.414344   \n",
       "whitePerCap                0.355572    -0.200691    -0.384188    -0.378667   \n",
       "blackPerCap                0.299927    -0.064154    -0.283802    -0.260035   \n",
       "indianPerCap               0.114807    -0.009973    -0.157383    -0.149951   \n",
       "AsianPerCap                0.095895    -0.113946    -0.265317    -0.325119   \n",
       "OtherPerCap                0.192715    -0.096380    -0.174010    -0.151272   \n",
       "HispPerCap                 0.199602    -0.239855    -0.311375    -0.321404   \n",
       "NumUnderPov                0.089707     0.196445     0.086405     0.177731   \n",
       "PctPopUnderPov            -0.173054     0.315825     0.500819     0.455564   \n",
       "PctLess9thGrade           -0.161614     0.543750     0.174316     0.147494   \n",
       "...                             ...          ...          ...          ...   \n",
       "MedNumBR                  -0.084585    -0.294034    -0.079190    -0.298290   \n",
       "HousVacant                 0.038811     0.104456    -0.047199     0.066072   \n",
       "PctHousOccup               0.248663    -0.080283     0.027777     0.016336   \n",
       "PctHousOwnOcc             -0.109821    -0.261729    -0.260620    -0.587321   \n",
       "PctVacantBoarded          -0.136218     0.164274     0.121929     0.099811   \n",
       "PctVacMore6Mos            -0.389248    -0.157279     0.035278    -0.148961   \n",
       "MedYrHousBuilt             0.074298     0.091944     0.104210     0.081225   \n",
       "PctHousNoPhone            -0.304801     0.274521     0.279850     0.220738   \n",
       "PctWOFullPlumb            -0.080564     0.369984     0.173942     0.150435   \n",
       "OwnOccLowQuart             0.584750     0.079199    -0.258728    -0.178608   \n",
       "OwnOccMedVal               0.587474     0.085324    -0.249730    -0.178391   \n",
       "OwnOccHiQuart              0.574134     0.076351    -0.242267    -0.184413   \n",
       "RentLowQ                   0.568032     0.070678    -0.297032    -0.159619   \n",
       "RentMedian                 0.546945     0.055650    -0.299337    -0.194770   \n",
       "RentHighQ                  0.537510     0.059832    -0.287044    -0.195122   \n",
       "MedRent                    0.509870     0.028163    -0.307269    -0.224061   \n",
       "MedRentPctHousInc          0.178857     0.287340     0.273049     0.275221   \n",
       "MedOwnCostPctInc           0.398443     0.336924    -0.171145    -0.016589   \n",
       "MedOwnCostPctIncNoMtg     -0.228924    -0.112096    -0.121343    -0.089328   \n",
       "NumInShelters              0.131252     0.113962    -0.005874     0.100686   \n",
       "NumStreet                  0.169384     0.157672    -0.024934     0.068469   \n",
       "PctForeignBorn             0.657352     0.684126    -0.068506     0.077395   \n",
       "PctBornSameState          -0.405063    -0.261949     0.080249    -0.047189   \n",
       "PctSameHouse85            -0.189265    -0.165463    -0.357267    -0.558953   \n",
       "PctSameCity85             -0.194646     0.014793    -0.361372    -0.505845   \n",
       "PctSameState85            -0.198114     0.000375    -0.150600    -0.317513   \n",
       "LandArea                  -0.001164     0.011568     0.025748     0.062408   \n",
       "PopDens                    0.389828     0.370002    -0.095728     0.119565   \n",
       "PctUsePubTrans             0.296805     0.078236    -0.173265    -0.023671   \n",
       "ViolentCrimesPerPop        0.037614     0.293065     0.060479     0.153362   \n",
       "\n",
       "                       agePct16t24  agePct65up         ...           \\\n",
       "population                0.075541   -0.101897         ...            \n",
       "householdsize             0.295154   -0.612600         ...            \n",
       "racepctblack              0.135043    0.051686         ...            \n",
       "racePctWhite             -0.184470    0.137636         ...            \n",
       "racePctAsian              0.052632   -0.271802         ...            \n",
       "racePctHisp               0.086239   -0.227504         ...            \n",
       "agePct12t21               0.894606   -0.411083         ...            \n",
       "agePct12t29               0.933727   -0.520506         ...            \n",
       "agePct16t24               1.000000   -0.322992         ...            \n",
       "agePct65up               -0.322992    1.000000         ...            \n",
       "numbUrban                 0.054485   -0.105883         ...            \n",
       "pctUrban                 -0.139297   -0.110738         ...            \n",
       "medIncome                -0.327212   -0.289694         ...            \n",
       "pctWWage                  0.103102   -0.838696         ...            \n",
       "pctWFarmSelf              0.144942   -0.158798         ...            \n",
       "pctWInvInc               -0.221821    0.076217         ...            \n",
       "pctWSocSec               -0.233191    0.941797         ...            \n",
       "pctWPubAsst               0.151366    0.142203         ...            \n",
       "pctWRetire               -0.271478    0.658000         ...            \n",
       "medFamInc                -0.259695   -0.224684         ...            \n",
       "perCapInc                -0.342344   -0.030757         ...            \n",
       "whitePerCap              -0.315009   -0.033370         ...            \n",
       "blackPerCap              -0.262010   -0.170252         ...            \n",
       "indianPerCap             -0.151153   -0.050408         ...            \n",
       "AsianPerCap              -0.275544    0.049929         ...            \n",
       "OtherPerCap              -0.161568   -0.112777         ...            \n",
       "HispPerCap               -0.279327   -0.030228         ...            \n",
       "NumUnderPov               0.135676   -0.062347         ...            \n",
       "PctPopUnderPov            0.472267    0.098800         ...            \n",
       "PctLess9thGrade           0.111562    0.196977         ...            \n",
       "...                            ...         ...         ...            \n",
       "MedNumBR                 -0.267915   -0.163774         ...            \n",
       "HousVacant                0.035427    0.038799         ...            \n",
       "PctHousOccup              0.000867   -0.277634         ...            \n",
       "PctHousOwnOcc            -0.487895    0.059392         ...            \n",
       "PctVacantBoarded          0.065746    0.024233         ...            \n",
       "PctVacMore6Mos           -0.076210    0.256085         ...            \n",
       "MedYrHousBuilt            0.005385   -0.421088         ...            \n",
       "PctHousNoPhone            0.201489    0.151656         ...            \n",
       "PctWOFullPlumb            0.115675    0.045130         ...            \n",
       "OwnOccLowQuart           -0.166238   -0.158990         ...            \n",
       "OwnOccMedVal             -0.158829   -0.149636         ...            \n",
       "OwnOccHiQuart            -0.152545   -0.128573         ...            \n",
       "RentLowQ                 -0.197852   -0.260477         ...            \n",
       "RentMedian               -0.207516   -0.225103         ...            \n",
       "RentHighQ                -0.197996   -0.218842         ...            \n",
       "MedRent                  -0.234780   -0.225534         ...            \n",
       "MedRentPctHousInc         0.337411    0.064800         ...            \n",
       "MedOwnCostPctInc         -0.098937   -0.215051         ...            \n",
       "MedOwnCostPctIncNoMtg    -0.078579    0.203016         ...            \n",
       "NumInShelters             0.068004   -0.032102         ...            \n",
       "NumStreet                 0.036995   -0.036585         ...            \n",
       "PctForeignBorn            0.005418   -0.139621         ...            \n",
       "PctBornSameState         -0.013581    0.149343         ...            \n",
       "PctSameHouse85           -0.462830    0.394105         ...            \n",
       "PctSameCity85            -0.479017    0.372693         ...            \n",
       "PctSameState85           -0.274456    0.255469         ...            \n",
       "LandArea                  0.031587   -0.124169         ...            \n",
       "PopDens                   0.045874    0.015682         ...            \n",
       "PctUsePubTrans           -0.040520    0.007002         ...            \n",
       "ViolentCrimesPerPop       0.099344    0.067199         ...            \n",
       "\n",
       "                       NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "population              0.651786        0.172637         -0.125008   \n",
       "householdsize          -0.043072        0.310962         -0.048983   \n",
       "racepctblack            0.167916       -0.096966          0.091961   \n",
       "racePctWhite           -0.239464       -0.374424          0.115216   \n",
       "racePctAsian            0.169384        0.657352         -0.405063   \n",
       "racePctHisp             0.157672        0.684126         -0.261949   \n",
       "agePct12t21            -0.024934       -0.068506          0.080249   \n",
       "agePct12t29             0.068469        0.077395         -0.047189   \n",
       "agePct16t24             0.036995        0.005418         -0.013581   \n",
       "agePct65up             -0.036585       -0.139621          0.149343   \n",
       "numbUrban               0.647347        0.194946         -0.140007   \n",
       "pctUrban                0.131550        0.292632         -0.232952   \n",
       "medIncome              -0.083965        0.227686         -0.244987   \n",
       "pctWWage               -0.046725        0.147896         -0.201546   \n",
       "pctWFarmSelf           -0.085129       -0.129928          0.081407   \n",
       "pctWInvInc             -0.125109       -0.037754         -0.134692   \n",
       "pctWSocSec             -0.056437       -0.195784          0.282247   \n",
       "pctWPubAsst             0.166082        0.129229          0.204189   \n",
       "pctWRetire             -0.067948       -0.205031          0.094712   \n",
       "medFamInc              -0.086261        0.198791         -0.238126   \n",
       "perCapInc              -0.028261        0.189381         -0.296931   \n",
       "whitePerCap             0.042606        0.231715         -0.314973   \n",
       "blackPerCap            -0.044414        0.226769         -0.183917   \n",
       "indianPerCap           -0.006817        0.103310         -0.126121   \n",
       "AsianPerCap            -0.041541        0.080861         -0.058688   \n",
       "OtherPerCap            -0.041669        0.116160         -0.145983   \n",
       "HispPerCap             -0.073177        0.086312         -0.153813   \n",
       "NumUnderPov             0.641195        0.135856         -0.055761   \n",
       "PctPopUnderPov          0.132607       -0.026376          0.152630   \n",
       "PctLess9thGrade         0.073074        0.232059          0.230260   \n",
       "...                          ...             ...               ...   \n",
       "MedNumBR               -0.187825       -0.267385          0.183813   \n",
       "HousVacant              0.595498        0.084518         -0.165341   \n",
       "PctHousOccup           -0.079233        0.105116          0.170854   \n",
       "PctHousOwnOcc          -0.230288       -0.226424          0.125130   \n",
       "PctVacantBoarded        0.219195       -0.047458          0.177153   \n",
       "PctVacMore6Mos         -0.072178       -0.318676          0.386178   \n",
       "MedYrHousBuilt         -0.049484       -0.032298         -0.352609   \n",
       "PctHousNoPhone          0.069642       -0.146178          0.196235   \n",
       "PctWOFullPlumb          0.146095        0.161381          0.122491   \n",
       "OwnOccLowQuart          0.038102        0.543471         -0.361738   \n",
       "OwnOccMedVal            0.056653        0.546922         -0.375572   \n",
       "OwnOccHiQuart           0.076572        0.532702         -0.389806   \n",
       "RentLowQ                0.012729        0.497059         -0.452058   \n",
       "RentMedian              0.015489        0.499604         -0.420259   \n",
       "RentHighQ               0.030894        0.504381         -0.420564   \n",
       "MedRent                -0.000264        0.459958         -0.399881   \n",
       "MedRentPctHousInc       0.128316        0.301422         -0.220473   \n",
       "MedOwnCostPctInc        0.127441        0.560820         -0.453341   \n",
       "MedOwnCostPctIncNoMtg  -0.038695       -0.029792          0.195751   \n",
       "NumInShelters           0.718986        0.140463         -0.091270   \n",
       "NumStreet               1.000000        0.203561         -0.148715   \n",
       "PctForeignBorn          0.203561        1.000000         -0.495517   \n",
       "PctBornSameState       -0.148715       -0.495517          1.000000   \n",
       "PctSameHouse85         -0.104463       -0.072741          0.473455   \n",
       "PctSameCity85          -0.015129       -0.023074          0.512720   \n",
       "PctSameState85         -0.079357       -0.137674          0.761715   \n",
       "LandArea                0.425937       -0.048959         -0.069166   \n",
       "PopDens                 0.238854        0.614694         -0.221114   \n",
       "PctUsePubTrans          0.239004        0.401597         -0.175249   \n",
       "ViolentCrimesPerPop     0.340277        0.194414         -0.077164   \n",
       "\n",
       "                       PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "population                  -0.123584       0.001761       -0.089559   \n",
       "householdsize               -0.057625      -0.102883       -0.003125   \n",
       "racepctblack                -0.047216       0.054900       -0.003852   \n",
       "racePctWhite                 0.166519      -0.018589        0.033114   \n",
       "racePctAsian                -0.189265      -0.194646       -0.198114   \n",
       "racePctHisp                 -0.165463       0.014793        0.000375   \n",
       "agePct12t21                 -0.357267      -0.361372       -0.150600   \n",
       "agePct12t29                 -0.558953      -0.505845       -0.317513   \n",
       "agePct16t24                 -0.462830      -0.479017       -0.274456   \n",
       "agePct65up                   0.394105       0.372693        0.255469   \n",
       "numbUrban                   -0.104999       0.013587       -0.089475   \n",
       "pctUrban                     0.097254       0.070739       -0.074317   \n",
       "medIncome                    0.249582      -0.005568       -0.051464   \n",
       "pctWWage                    -0.187224      -0.301125       -0.241418   \n",
       "pctWFarmSelf                -0.138527      -0.162278        0.011407   \n",
       "pctWInvInc                   0.255047      -0.053952       -0.074027   \n",
       "pctWSocSec                   0.437809       0.434151        0.356144   \n",
       "pctWPubAsst                 -0.053344       0.218824        0.210388   \n",
       "pctWRetire                   0.378977       0.260235        0.167277   \n",
       "medFamInc                    0.229966      -0.040818       -0.068901   \n",
       "perCapInc                    0.216965      -0.023194       -0.119385   \n",
       "whitePerCap                  0.184989      -0.025422       -0.136007   \n",
       "blackPerCap                  0.183147       0.022653       -0.030075   \n",
       "indianPerCap                 0.047506      -0.014866       -0.025912   \n",
       "AsianPerCap                  0.231919       0.129662        0.069164   \n",
       "OtherPerCap                  0.086661      -0.028959       -0.047641   \n",
       "HispPerCap                   0.243155       0.052421       -0.030592   \n",
       "NumUnderPov                 -0.116689       0.033049       -0.046699   \n",
       "PctPopUnderPov              -0.264225      -0.052178        0.017108   \n",
       "PctLess9thGrade              0.092012       0.299533        0.272570   \n",
       "...                               ...            ...             ...   \n",
       "MedNumBR                     0.311718       0.137198        0.158384   \n",
       "HousVacant                  -0.151376      -0.034030       -0.142461   \n",
       "PctHousOccup                 0.228462       0.156613        0.207373   \n",
       "PctHousOwnOcc                0.514294       0.267242        0.278335   \n",
       "PctVacantBoarded             0.112447       0.247518        0.188278   \n",
       "PctVacMore6Mos               0.394716       0.326764        0.315617   \n",
       "MedYrHousBuilt              -0.495242      -0.483788       -0.363762   \n",
       "PctHousNoPhone              -0.152454       0.069812        0.076350   \n",
       "PctWOFullPlumb               0.018888       0.153390        0.119830   \n",
       "OwnOccLowQuart               0.129316      -0.031608       -0.090975   \n",
       "OwnOccMedVal                 0.110653      -0.045764       -0.108123   \n",
       "OwnOccHiQuart                0.092198      -0.061083       -0.131252   \n",
       "RentLowQ                     0.002758      -0.144318       -0.179558   \n",
       "RentMedian                   0.082493      -0.097129       -0.143384   \n",
       "RentHighQ                    0.096489      -0.101541       -0.149243   \n",
       "MedRent                      0.104751      -0.086725       -0.130475   \n",
       "MedRentPctHousInc           -0.251303      -0.196164       -0.096873   \n",
       "MedOwnCostPctInc            -0.182908      -0.198099       -0.216482   \n",
       "MedOwnCostPctIncNoMtg        0.345228       0.224752        0.186936   \n",
       "NumInShelters               -0.081306       0.014734       -0.065202   \n",
       "NumStreet                   -0.104463      -0.015129       -0.079357   \n",
       "PctForeignBorn              -0.072741      -0.023074       -0.137674   \n",
       "PctBornSameState             0.473455       0.512720        0.761715   \n",
       "PctSameHouse85               1.000000       0.803016        0.670899   \n",
       "PctSameCity85                0.803016       1.000000        0.741996   \n",
       "PctSameState85               0.670899       0.741996        1.000000   \n",
       "LandArea                    -0.116822      -0.062889       -0.104345   \n",
       "PopDens                      0.020961       0.118405       -0.012001   \n",
       "PctUsePubTrans               0.192641       0.081535       -0.042284   \n",
       "ViolentCrimesPerPop         -0.155405       0.075595       -0.019450   \n",
       "\n",
       "                       LandArea   PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "population             0.713643  0.231838        0.270305             0.367160  \n",
       "householdsize         -0.015138 -0.004214       -0.051637            -0.034934  \n",
       "racepctblack           0.150503  0.096183        0.148176             0.632904  \n",
       "racePctWhite          -0.131802 -0.338501       -0.216444            -0.685631  \n",
       "racePctAsian          -0.001164  0.389828        0.296805             0.037614  \n",
       "racePctHisp            0.011568  0.370002        0.078236             0.293065  \n",
       "agePct12t21            0.025748 -0.095728       -0.173265             0.060479  \n",
       "agePct12t29            0.062408  0.119565       -0.023671             0.153362  \n",
       "agePct16t24            0.031587  0.045874       -0.040520             0.099344  \n",
       "agePct65up            -0.124169  0.015682        0.007002             0.067199  \n",
       "numbUrban              0.693439  0.258044        0.298111             0.362912  \n",
       "pctUrban               0.080914  0.330905        0.343409             0.082049  \n",
       "medIncome             -0.047549 -0.024034        0.250257            -0.424422  \n",
       "pctWWage               0.060993 -0.034848        0.084254            -0.305763  \n",
       "pctWFarmSelf          -0.011216 -0.265205       -0.244865            -0.153123  \n",
       "pctWInvInc            -0.073307 -0.114247        0.161068            -0.576499  \n",
       "pctWSocSec            -0.126963 -0.024207       -0.058103             0.118026  \n",
       "pctWPubAsst            0.030730  0.197866       -0.015947             0.575327  \n",
       "pctWRetire            -0.052642 -0.087981       -0.040556            -0.098441  \n",
       "medFamInc             -0.058154 -0.017385        0.275162            -0.439313  \n",
       "perCapInc             -0.033938  0.018880        0.307742            -0.352170  \n",
       "whitePerCap            0.020059  0.064175        0.360911            -0.209280  \n",
       "blackPerCap           -0.058515  0.074220        0.226187            -0.275452  \n",
       "indianPerCap          -0.018141  0.040204        0.091772            -0.090880  \n",
       "AsianPerCap           -0.041184 -0.025089        0.124098            -0.155590  \n",
       "OtherPerCap           -0.010158  0.029342        0.146859            -0.126345  \n",
       "HispPerCap            -0.041458 -0.013475        0.215542            -0.244639  \n",
       "NumUnderPov            0.649900  0.227736        0.258572             0.447581  \n",
       "PctPopUnderPov         0.066514  0.065777       -0.108570             0.522670  \n",
       "PctLess9thGrade       -0.042898  0.181251       -0.080374             0.411228  \n",
       "...                         ...       ...             ...                  ...  \n",
       "MedNumBR              -0.055292 -0.311522       -0.109614            -0.357420  \n",
       "HousVacant             0.700787  0.150503        0.215275             0.421396  \n",
       "PctHousOccup          -0.177257  0.140246        0.117863            -0.319112  \n",
       "PctHousOwnOcc         -0.041544 -0.448368       -0.196144            -0.470683  \n",
       "PctVacantBoarded       0.220112  0.128895        0.138658             0.482853  \n",
       "PctVacMore6Mos         0.028985 -0.196966       -0.036737             0.021314  \n",
       "MedYrHousBuilt         0.137922 -0.410634       -0.391554            -0.110010  \n",
       "PctHousNoPhone         0.049198 -0.059114       -0.202486             0.488386  \n",
       "PctWOFullPlumb         0.080075  0.163849        0.054767             0.364682  \n",
       "OwnOccLowQuart        -0.086487  0.278326        0.391054            -0.210610  \n",
       "OwnOccMedVal          -0.074714  0.275894        0.394247            -0.190776  \n",
       "OwnOccHiQuart         -0.056469  0.259238        0.391711            -0.172164  \n",
       "RentLowQ              -0.059525  0.251077        0.325284            -0.252032  \n",
       "RentMedian            -0.054105  0.231813        0.368063            -0.240654  \n",
       "RentHighQ             -0.040882  0.234664        0.387958            -0.232405  \n",
       "MedRent               -0.048723  0.187567        0.338039            -0.239985  \n",
       "MedRentPctHousInc      0.027898  0.216797        0.102031             0.325091  \n",
       "MedOwnCostPctInc       0.036908  0.299438        0.254961             0.063846  \n",
       "MedOwnCostPctIncNoMtg -0.028060  0.128711        0.313671             0.053841  \n",
       "NumInShelters          0.526500  0.243914        0.332407             0.375757  \n",
       "NumStreet              0.425937  0.238854        0.239004             0.340277  \n",
       "PctForeignBorn        -0.048959  0.614694        0.401597             0.194414  \n",
       "PctBornSameState      -0.069166 -0.221114       -0.175249            -0.077164  \n",
       "PctSameHouse85        -0.116822  0.020961        0.192641            -0.155405  \n",
       "PctSameCity85         -0.062889  0.118405        0.081535             0.075595  \n",
       "PctSameState85        -0.104345 -0.012001       -0.042284            -0.019450  \n",
       "LandArea               1.000000 -0.170936        0.007643             0.196799  \n",
       "PopDens               -0.170936  1.000000        0.587749             0.281402  \n",
       "PctUsePubTrans         0.007643  0.587749        1.000000             0.153830  \n",
       "ViolentCrimesPerPop    0.196799  0.281402        0.153830             1.000000  \n",
       "\n",
       "[98 rows x 98 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I can also look at pearson correlation:\n",
    "communities_matrix.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix is huge so I would have to look at individual variables to see how or if they are correlated, I can see how feature selection will be beneficial as I consider the models I choose to use for regression analysis based on how many variables we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will convert the dataframe into a np.array to use with our regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(communities_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19  0.33  0.02 ...,  0.26  0.2   0.2 ]\n",
      " [ 0.    0.16  0.12 ...,  0.12  0.45  0.67]\n",
      " [ 0.    0.42  0.49 ...,  0.21  0.02  0.43]\n",
      " ..., \n",
      " [ 0.16  0.37  0.25 ...,  0.32  0.18  0.23]\n",
      " [ 0.08  0.51  0.06 ...,  0.38  0.33  0.19]\n",
      " [ 0.2   0.78  0.14 ...,  0.3   0.05  0.48]]\n"
     ]
    }
   ],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1993, 98)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # see that the nan row was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the target variable data into its own array\n",
    "target = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2   0.67  0.43 ...,  0.23  0.19  0.48]\n"
     ]
    }
   ],
   "source": [
    "print target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove target variable from the training matrix\n",
    "train_data = data[:, :97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19  0.33  0.02 ...,  0.12  0.26  0.2 ]\n",
      " [ 0.    0.16  0.12 ...,  0.02  0.12  0.45]\n",
      " [ 0.    0.42  0.49 ...,  0.01  0.21  0.02]\n",
      " ..., \n",
      " [ 0.16  0.37  0.25 ...,  0.08  0.32  0.18]\n",
      " [ 0.08  0.51  0.06 ...,  0.03  0.38  0.33]\n",
      " [ 0.2   0.78  0.14 ...,  0.11  0.3   0.05]]\n"
     ]
    }
   ],
   "source": [
    "print train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Perform standard linear regression on data using the implementation for Ch. 8 of MLA. Compute the RMSE value on the full training data. Also, plot the correlation between the predicted and actual values of the target attribute. Display the obtained regression coefficients (weights). Finally, perform 10-fold cross-validation and compare the cross-validation RMSE to the training RMSE (for cross validation, you should use the KFold module from sklearn.cross_validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb\n",
    "\n",
    "# This is the code from our Professor's notebook with my own notes added for better understanding\n",
    "# standard linear regression:\n",
    "# this function computes the best line fit by returning the regression weights as a vector of w values\n",
    "# This basically uses closed form solution for least squares method\n",
    "# passes xArr, yArr - our x,y - these are np arrays\n",
    "# inside the function it turns it into the matrix\n",
    "# internally is just a 2-d array\n",
    "# .mat has certain functions that are not available with np.arrays\n",
    "\n",
    "def standRegres(xArr,yArr):\n",
    "    \n",
    "#     pdb.set_trace() # python debugger that I'm using to find my error\n",
    "    \n",
    "    xMat = np.mat(xArr); yMat = np.mat(yArr).T # turns np.arrays into matrixes\n",
    "    xTx = xMat.T*xMat # if we had np.arrays, this would just be element-wise multiplication\n",
    "    # vs matrixes - wherein this is matrix multiplication: multiplying x * x.T(in slides)\n",
    "    \n",
    "    # now we need to find the inverse:\n",
    "    # but if determinant of matrix is 0, then it cannot compute\n",
    "    # so we print an error\n",
    "    if np.linalg.det(xTx) == 0.0: # linear algebra library that gives us the determinate\n",
    "        print \"This matrix is singular, cannot do inverse\"\n",
    "        return\n",
    "    \n",
    "    # otherwise, compute inverse and then do matrix multiplication \n",
    "    # close form solution for standard linear regression\n",
    "    ws = xTx.I * (xMat.T*yMat)\n",
    "    return ws # returns the vector of w values\n",
    "\n",
    "# the way you can use this is by calling this function on x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to do multiple regression we need to add a column of 1s for x0 - see slide 7 of regression slides\n",
    "# to do this we are concatenating a one to each row of the array at the end\n",
    "# v represents a vector in our data\n",
    "# so then we will get all the data with the 1 at the end - see below\n",
    "x = np.array([np.concatenate((v,[1.0])) for v in train_data]) # x is matrix\n",
    "y = target # y is response var - we are keeping consistent with algorithms by using x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19  0.33  0.02  0.9   0.12  0.17  0.34  0.47  0.29  0.32  0.2   1.\n",
      "   0.37  0.72  0.34  0.6   0.29  0.15  0.43  0.39  0.4   0.39  0.32  0.27\n",
      "   0.27  0.36  0.41  0.08  0.19  0.1   0.18  0.48  0.27  0.68  0.23  0.41\n",
      "   0.68  0.4   0.75  0.75  0.35  0.55  0.59  0.61  0.56  0.74  0.76  0.04\n",
      "   0.14  0.03  0.24  0.27  0.37  0.39  0.07  0.07  0.08  0.08  0.89  0.06\n",
      "   0.14  0.13  0.33  0.39  0.28  0.55  0.09  0.51  0.5   0.21  0.71  0.52\n",
      "   0.05  0.26  0.65  0.14  0.06  0.22  0.19  0.18  0.36  0.35  0.38  0.34\n",
      "   0.38  0.46  0.25  0.04  0.    0.12  0.42  0.5   0.51  0.64  0.12  0.26\n",
      "   0.2   1.  ]\n",
      " [ 0.    0.16  0.12  0.74  0.45  0.07  0.26  0.59  0.35  0.27  0.02  1.\n",
      "   0.31  0.72  0.11  0.45  0.25  0.29  0.39  0.29  0.37  0.38  0.33  0.16\n",
      "   0.3   0.22  0.35  0.01  0.24  0.14  0.24  0.3   0.27  0.73  0.57  0.15\n",
      "   1.    0.63  0.91  1.    0.29  0.43  0.47  0.6   0.39  0.46  0.53  0.\n",
      "   0.24  0.01  0.52  0.62  0.64  0.63  0.25  0.27  0.25  0.23  0.84  0.1\n",
      "   0.16  0.1   0.17  0.29  0.17  0.26  0.2   0.82  0.    0.02  0.79  0.24\n",
      "   0.02  0.25  0.65  0.16  0.    0.21  0.2   0.21  0.42  0.38  0.4   0.37\n",
      "   0.29  0.32  0.18  0.    0.    0.21  0.5   0.34  0.6   0.52  0.02  0.12\n",
      "   0.45  1.  ]\n",
      " [ 0.    0.42  0.49  0.56  0.17  0.04  0.39  0.47  0.28  0.32  0.    0.\n",
      "   0.3   0.58  0.19  0.39  0.38  0.4   0.84  0.28  0.27  0.29  0.27  0.07\n",
      "   0.29  0.28  0.39  0.01  0.27  0.27  0.43  0.19  0.36  0.58  0.32  0.29\n",
      "   0.63  0.41  0.71  0.7   0.45  0.42  0.44  0.43  0.43  0.71  0.67  0.01\n",
      "   0.46  0.    0.07  0.06  0.15  0.19  0.02  0.02  0.04  0.05  0.88  0.04\n",
      "   0.2   0.2   0.46  0.52  0.43  0.42  0.15  0.51  0.5   0.01  0.86  0.41\n",
      "   0.29  0.3   0.52  0.47  0.45  0.18  0.17  0.16  0.27  0.29  0.27  0.31\n",
      "   0.48  0.39  0.28  0.    0.    0.14  0.49  0.54  0.67  0.56  0.01  0.21\n",
      "   0.02  1.  ]\n",
      " [ 0.04  0.77  1.    0.08  0.12  0.1   0.51  0.5   0.34  0.21  0.06  1.\n",
      "   0.58  0.89  0.21  0.43  0.36  0.2   0.82  0.51  0.36  0.4   0.39  0.16\n",
      "   0.25  0.36  0.44  0.01  0.1   0.09  0.25  0.31  0.33  0.71  0.36  0.45\n",
      "   0.34  0.45  0.49  0.44  0.75  0.65  0.54  0.83  0.65  0.85  0.86  0.03\n",
      "   0.33  0.02  0.11  0.2   0.3   0.31  0.05  0.08  0.11  0.11  0.81  0.08\n",
      "   0.56  0.62  0.85  0.77  1.    0.94  0.12  0.01  0.5   0.01  0.97  0.96\n",
      "   0.6   0.47  0.52  0.11  0.11  0.24  0.21  0.19  0.75  0.7   0.77  0.89\n",
      "   0.63  0.51  0.47  0.    0.    0.19  0.3   0.73  0.64  0.65  0.02  0.39\n",
      "   0.28  1.  ]\n",
      " [ 0.01  0.55  0.02  0.95  0.09  0.05  0.38  0.38  0.23  0.36  0.02  0.9\n",
      "   0.5   0.72  0.16  0.68  0.44  0.11  0.71  0.46  0.43  0.41  0.28  0.\n",
      "   0.74  0.51  0.48  0.    0.06  0.25  0.3   0.33  0.12  0.65  0.67  0.38\n",
      "   0.22  0.27  0.2   0.21  0.51  0.91  0.91  0.89  0.85  0.4   0.6   0.\n",
      "   0.06  0.    0.03  0.07  0.2   0.27  0.01  0.02  0.04  0.05  0.88  0.05\n",
      "   0.16  0.19  0.59  0.6   0.37  0.89  0.02  0.19  0.5   0.01  0.89  0.87\n",
      "   0.04  0.55  0.73  0.05  0.14  0.31  0.31  0.3   0.4   0.36  0.38  0.38\n",
      "   0.22  0.51  0.21  0.    0.    0.11  0.72  0.64  0.61  0.53  0.04  0.09\n",
      "   0.02  1.  ]\n",
      " [ 0.02  0.28  0.06  0.54  1.    0.25  0.31  0.48  0.27  0.37  0.04  1.\n",
      "   0.52  0.68  0.2   0.61  0.28  0.15  0.25  0.62  0.72  0.76  0.77  0.28\n",
      "   0.52  0.48  0.6   0.01  0.12  0.13  0.12  0.8   0.1   0.65  0.19  0.77\n",
      "   0.49  0.57  0.61  0.58  0.44  0.62  0.69  0.87  0.53  0.3   0.43  0.\n",
      "   0.11  0.04  0.3   0.35  0.43  0.47  0.5   0.5   0.56  0.57  0.45  0.28\n",
      "   0.25  0.19  0.29  0.53  0.18  0.39  0.26  0.73  0.    0.02  0.84  0.3\n",
      "   0.16  0.28  0.25  0.02  0.05  0.94  1.    1.    0.67  0.63  0.68  0.62\n",
      "   0.47  0.59  0.11  0.    0.    0.7   0.42  0.49  0.73  0.64  0.01  0.58\n",
      "   0.1   1.  ]\n",
      " [ 0.01  0.39  0.    0.98  0.06  0.02  0.3   0.37  0.23  0.6   0.02  0.81\n",
      "   0.42  0.5   0.23  0.68  0.61  0.21  0.54  0.43  0.47  0.44  0.4   0.24\n",
      "   0.86  0.24  0.36  0.01  0.11  0.29  0.41  0.36  0.28  0.54  0.44  0.53\n",
      "   0.25  0.34  0.28  0.28  0.42  0.77  0.81  0.79  0.74  0.57  0.62  0.\n",
      "   0.13  0.01  0.    0.02  0.02  0.1   0.    0.01  0.01  0.03  0.73  0.05\n",
      "   0.12  0.13  0.42  0.54  0.24  0.65  0.03  0.46  0.5   0.01  0.89  0.57\n",
      "   0.09  0.49  0.38  0.05  0.05  0.37  0.38  0.39  0.26  0.35  0.42  0.35\n",
      "   0.46  0.44  0.31  0.    0.    0.15  0.81  0.77  0.91  0.84  0.05  0.08\n",
      "   0.06  1.  ]\n",
      " [ 0.01  0.74  0.03  0.46  0.2   1.    0.52  0.55  0.36  0.35  0.    0.\n",
      "   0.16  0.44  1.    0.23  0.53  0.97  0.41  0.15  0.1   0.12  0.08  0.17\n",
      "   0.27  0.18  0.21  0.03  0.64  0.96  0.82  0.12  1.    0.26  0.43  0.34\n",
      "   0.38  0.47  0.59  0.52  0.78  0.45  0.43  0.34  0.34  0.29  0.27  0.02\n",
      "   0.5   0.02  0.5   0.59  0.65  0.59  0.69  0.72  0.71  0.6   0.12  0.93\n",
      "   0.74  0.75  0.8   0.68  0.92  0.39  0.89  0.66  0.    0.01  0.91  0.46\n",
      "   0.22  0.37  0.6   0.28  0.23  0.15  0.13  0.13  0.21  0.24  0.25  0.24\n",
      "   0.64  0.59  0.28  0.    0.    0.59  0.58  0.52  0.79  0.78  0.01  0.33\n",
      "   0.    1.  ]\n",
      " [ 0.03  0.34  0.2   0.84  0.02  0.    0.38  0.45  0.28  0.48  0.04  1.\n",
      "   0.17  0.47  0.36  0.34  0.55  0.48  0.43  0.21  0.23  0.23  0.19  0.1\n",
      "   0.26  0.29  0.22  0.04  0.45  0.52  0.59  0.17  0.55  0.43  0.59  0.36\n",
      "   0.62  0.26  0.66  0.67  0.37  0.51  0.55  0.58  0.47  0.65  0.64  0.02\n",
      "   0.29  0.    0.12  0.09  0.07  0.13  0.    0.    0.    0.    0.99  0.01\n",
      "   0.12  0.12  0.35  0.38  0.33  0.5   0.1   0.64  0.    0.04  0.72  0.49\n",
      "   0.05  0.49  0.5   0.57  0.22  0.07  0.07  0.08  0.14  0.17  0.16  0.15\n",
      "   0.38  0.13  0.36  0.01  0.    0.01  0.78  0.48  0.79  0.75  0.04  0.17\n",
      "   0.04  1.  ]\n",
      " [ 0.01  0.4   0.06  0.87  0.3   0.03  0.9   0.82  0.8   0.39  0.02  1.\n",
      "   0.54  0.59  0.22  0.86  0.42  0.02  0.31  0.85  0.89  0.94  0.11  0.09\n",
      "   0.33  0.17  0.8   0.    0.11  0.04  0.03  1.    0.11  0.44  0.2   1.\n",
      "   0.3   0.85  0.39  0.36  0.31  0.65  0.73  0.78  0.67  0.72  0.71  0.\n",
      "   0.07  0.01  0.41  0.44  0.52  0.48  0.22  0.21  0.22  0.19  0.85  0.03\n",
      "   0.09  0.06  0.15  0.34  0.05  0.48  0.03  0.58  0.    0.02  0.72  0.38\n",
      "   0.07  0.47  0.04  0.01  0.    0.63  0.71  0.79  0.44  0.42  0.47  0.41\n",
      "   0.23  0.27  0.28  0.    0.    0.22  0.42  0.34  0.23  0.09  0.    0.47\n",
      "   0.11  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# looking at first 10 rows of our matrix x\n",
    "# and we can see that there is a 1 at the end of each row\n",
    "print x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2   0.67  0.43  0.12  0.03  0.14  0.03  0.55  0.53  0.15]\n"
     ]
    }
   ],
   "source": [
    "# View first ten elements of the target data\n",
    "print y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm really unsure if I need to do this yet\n",
    "\n",
    "# split data into training and test\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x, x_test, y, y_test = train_test_split(x, y, test_size=0.2, random_state=33)\n",
    "# get randomized 80/20 split\n",
    "# all cross-val doing - doing on training\n",
    "# run on test data as final step just to see accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are getting our vector of regression weights by passing in x and y\n",
    "w = standRegres(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.23274125e-01]\n",
      " [  6.75179555e-03]\n",
      " [  2.30380105e-01]\n",
      " [  1.19090859e-02]\n",
      " [  2.23184672e-03]\n",
      " [  1.03141096e-01]\n",
      " [  1.74785968e-01]\n",
      " [ -2.95684337e-01]\n",
      " [ -1.50353957e-01]\n",
      " [  1.06324388e-01]\n",
      " [  6.27284543e-02]\n",
      " [  4.18333159e-02]\n",
      " [ -1.27178914e-01]\n",
      " [ -3.02481695e-01]\n",
      " [  3.17482567e-02]\n",
      " [ -1.82704491e-01]\n",
      " [ -6.22150671e-02]\n",
      " [  2.04305861e-02]\n",
      " [ -7.86345616e-02]\n",
      " [  1.47145551e-01]\n",
      " [  9.37761711e-03]\n",
      " [ -1.40064473e-01]\n",
      " [ -2.19732896e-02]\n",
      " [ -3.10570337e-02]\n",
      " [  1.70178754e-02]\n",
      " [  2.84278945e-02]\n",
      " [  3.76389589e-02]\n",
      " [  1.52989956e-01]\n",
      " [ -1.95656878e-01]\n",
      " [ -1.10977370e-01]\n",
      " [  6.88207406e-02]\n",
      " [  9.40507991e-02]\n",
      " [  3.55343798e-02]\n",
      " [  2.87584105e-01]\n",
      " [ -1.93113730e-02]\n",
      " [ -1.39061270e-02]\n",
      " [  3.62876056e-01]\n",
      " [  2.59733194e-01]\n",
      " [ -3.53559980e-02]\n",
      " [ -2.76849870e-01]\n",
      " [ -6.68238876e-02]\n",
      " [  8.06394517e-02]\n",
      " [ -3.33432611e-01]\n",
      " [ -2.78871594e-02]\n",
      " [ -9.79507415e-03]\n",
      " [  6.57579495e-02]\n",
      " [ -1.91489610e-01]\n",
      " [ -2.34402322e-01]\n",
      " [  1.45490323e-01]\n",
      " [ -9.28827172e-02]\n",
      " [  4.29715572e-02]\n",
      " [  4.78269677e-02]\n",
      " [ -1.04016599e-01]\n",
      " [  5.21765256e-02]\n",
      " [ -5.41566428e-02]\n",
      " [ -2.69720598e-01]\n",
      " [  6.06306320e-01]\n",
      " [ -3.05519055e-01]\n",
      " [  3.04490608e-03]\n",
      " [ -1.48641483e-01]\n",
      " [ -1.10929542e-01]\n",
      " [ -4.16292268e-02]\n",
      " [  4.65243515e-01]\n",
      " [  4.93554192e-02]\n",
      " [ -2.88217249e-01]\n",
      " [ -9.52290130e-01]\n",
      " [  1.97785936e-01]\n",
      " [  1.28053458e-01]\n",
      " [  2.21768047e-02]\n",
      " [  1.09867470e-01]\n",
      " [ -5.08158833e-02]\n",
      " [  8.47013558e-01]\n",
      " [  5.05607552e-02]\n",
      " [ -6.10038547e-02]\n",
      " [ -9.89461424e-03]\n",
      " [ -2.64947879e-04]\n",
      " [ -9.60089697e-03]\n",
      " [ -3.71138686e-01]\n",
      " [  4.52027154e-01]\n",
      " [ -1.46281922e-01]\n",
      " [ -2.36384451e-01]\n",
      " [ -9.96566067e-03]\n",
      " [ -9.08828754e-02]\n",
      " [  3.70974015e-01]\n",
      " [  6.56500708e-02]\n",
      " [ -7.24676689e-02]\n",
      " [ -8.65905749e-02]\n",
      " [  1.59665652e-01]\n",
      " [  1.38731735e-01]\n",
      " [  1.17427233e-01]\n",
      " [  1.78514670e-02]\n",
      " [  9.70454437e-04]\n",
      " [  2.60463611e-02]\n",
      " [ -2.02858762e-02]\n",
      " [  1.61847850e-02]\n",
      " [  7.58514430e-03]\n",
      " [ -4.62914805e-02]\n",
      " [  5.04172309e-01]]\n"
     ]
    }
   ],
   "source": [
    "print w # this is our 1-d vector of regression weights\n",
    "# w's are weights according to features\n",
    "# can be positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that I have the weights, I can find the predicted value for y using following code\n",
    "# which I will then plot:\n",
    "# using code from the book pg. 158\n",
    "\n",
    "xMat = np.mat(x)\n",
    "yMat = np.mat(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted y's\n",
    "yHat = xMat*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32888552]\n",
      " [ 0.25656182]\n",
      " [ 0.01018449]\n",
      " [-0.04678201]\n",
      " [ 0.27344635]\n",
      " [ 0.09930385]\n",
      " [ 0.34001867]\n",
      " [ 0.06481784]\n",
      " [ 0.21854776]\n",
      " [ 0.16179036]]\n"
     ]
    }
   ],
   "source": [
    "# Here are our predicted values\n",
    "print yHat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31]\n",
      " [ 0.05]\n",
      " [ 0.22]\n",
      " [ 0.1 ]\n",
      " [ 0.31]\n",
      " [ 0.19]\n",
      " [ 0.52]\n",
      " [ 0.08]\n",
      " [ 0.22]\n",
      " [ 0.71]]\n"
     ]
    }
   ],
   "source": [
    "# Here are our actual values\n",
    "print yMat.T[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where I got stuck for hours, ugh!\n",
    "# The book gives us output in column-matrix format\n",
    "# if we want the same format as sklearn,\n",
    "# a 1-d array,\n",
    "# we need to do the following code:\n",
    "p = yHat.A.ravel() \n",
    "# yHat.A - gives you the array portion, then the \n",
    "#.ravel() flattens a 2-d array into 1-d array b/c we see above that we have a 2-d matrix\n",
    "# but doesn't change it permanently so putting into variable p for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32888552  0.25656182  0.01018449 ...,  0.35402712  0.28346037\n",
      "  0.03441544]\n"
     ]
    }
   ],
   "source": [
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find the error which is based on difference between actual response vars, and predicted response vars\n",
    "# diff between p and y values\n",
    "# Compute RMSE using steps from class notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = abs(p - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01888552  0.20656182  0.20981551  0.14678201  0.03655365  0.09069615\n",
      "  0.17998133  0.01518216  0.00145224  0.54820964]\n"
     ]
    }
   ],
   "source": [
    "# Let's see the error on the first 10 predictions\n",
    "print err[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to compute the sum of squared errors:\n",
    "# multiply error values with themselves - same as squaring error\n",
    "# and add them up - is the formula for finding the dot product between the err and err\n",
    "# Formula:\n",
    "# Dot product of error vector with itself gives us the sum of squared errors\n",
    "total_error = np.dot(err,err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.9234289929\n"
     ]
    }
   ],
   "source": [
    "print total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12752697698\n"
     ]
    }
   ],
   "source": [
    "# Now we have all the information that we need to comput RMSE\n",
    "\n",
    "# Compute RMSE - root mean square error formula:\n",
    "# remember this is the rmse on the training data\n",
    "rmse_train = np.sqrt(total_error/len(p)) # square root of sum of squared errors divided by N or total number of values\n",
    "print rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to sort our y's\n",
    "xCopy = xMat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCopy.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1594, 98)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xCopy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted values but using sort:\n",
    "yHat = xCopy*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0a107110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the predicted values yHat with y\n",
    "# using code from book on page 158\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(yMat.T[:,0].flatten().A[0], yHat[:,0].flatten().A[0])\n",
    "#ax.plot(yMat, yHat) # this is creating a crazy visualization with multiple lines, not sure how to get one line \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrixlib.defmatrix.matrix"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once again I need to change the 2-d matrix of regression weights\n",
    "w = w.A.ravel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12327412  0.0067518   0.2303801   0.01190909  0.00223185  0.1031411\n",
      "  0.17478597 -0.29568434 -0.15035396  0.10632439]\n"
     ]
    }
   ],
   "source": [
    "print w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['population',\n",
       " 'householdsize',\n",
       " 'racepctblack',\n",
       " 'racePctWhite',\n",
       " 'racePctAsian',\n",
       " 'racePctHisp',\n",
       " 'agePct12t21',\n",
       " 'agePct12t29',\n",
       " 'agePct16t24',\n",
       " 'agePct65up',\n",
       " 'numbUrban',\n",
       " 'pctUrban',\n",
       " 'medIncome',\n",
       " 'pctWWage',\n",
       " 'pctWFarmSelf',\n",
       " 'pctWInvInc',\n",
       " 'pctWSocSec',\n",
       " 'pctWPubAsst',\n",
       " 'pctWRetire',\n",
       " 'medFamInc',\n",
       " 'perCapInc',\n",
       " 'whitePerCap',\n",
       " 'blackPerCap',\n",
       " 'indianPerCap',\n",
       " 'AsianPerCap',\n",
       " 'OtherPerCap',\n",
       " 'HispPerCap',\n",
       " 'NumUnderPov',\n",
       " 'PctPopUnderPov',\n",
       " 'PctLess9thGrade',\n",
       " 'PctNotHSGrad',\n",
       " 'PctBSorMore',\n",
       " 'PctUnemployed',\n",
       " 'PctEmploy',\n",
       " 'PctEmplManu',\n",
       " 'PctEmplProfServ',\n",
       " 'MalePctDivorce',\n",
       " 'MalePctNevMarr',\n",
       " 'FemalePctDiv',\n",
       " 'TotalPctDiv',\n",
       " 'PersPerFam',\n",
       " 'PctFam2Par',\n",
       " 'PctKids2Par',\n",
       " 'PctYoungKids2Par',\n",
       " 'PctTeen2Par',\n",
       " 'PctWorkMomYoungKids',\n",
       " 'PctWorkMom',\n",
       " 'NumIlleg',\n",
       " 'PctIlleg',\n",
       " 'NumImmig',\n",
       " 'PctImmigRecent',\n",
       " 'PctImmigRec5',\n",
       " 'PctImmigRec8',\n",
       " 'PctImmigRec10',\n",
       " 'PctRecentImmig',\n",
       " 'PctRecImmig5',\n",
       " 'PctRecImmig8',\n",
       " 'PctRecImmig10',\n",
       " 'PctSpeakEnglOnly',\n",
       " 'PctNotSpeakEnglWell',\n",
       " 'PctLargHouseFam',\n",
       " 'PctLargHouseOccup',\n",
       " 'PersPerOccupHous',\n",
       " 'PersPerOwnOccHous',\n",
       " 'PersPerRentOccHous',\n",
       " 'PctPersOwnOccup',\n",
       " 'PctPersDenseHous',\n",
       " 'PctHousLess3BR',\n",
       " 'MedNumBR',\n",
       " 'HousVacant',\n",
       " 'PctHousOccup',\n",
       " 'PctHousOwnOcc',\n",
       " 'PctVacantBoarded',\n",
       " 'PctVacMore6Mos',\n",
       " 'MedYrHousBuilt',\n",
       " 'PctHousNoPhone',\n",
       " 'PctWOFullPlumb',\n",
       " 'OwnOccLowQuart',\n",
       " 'OwnOccMedVal',\n",
       " 'OwnOccHiQuart',\n",
       " 'RentLowQ',\n",
       " 'RentMedian',\n",
       " 'RentHighQ',\n",
       " 'MedRent',\n",
       " 'MedRentPctHousInc',\n",
       " 'MedOwnCostPctInc',\n",
       " 'MedOwnCostPctIncNoMtg',\n",
       " 'NumInShelters',\n",
       " 'NumStreet',\n",
       " 'PctForeignBorn',\n",
       " 'PctBornSameState',\n",
       " 'PctSameHouse85',\n",
       " 'PctSameCity85',\n",
       " 'PctSameState85',\n",
       " 'LandArea',\n",
       " 'PopDens',\n",
       " 'PctUsePubTrans',\n",
       " 'ViolentCrimesPerPop']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 98)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0ff29f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can plot the importance of the features with the method \n",
    "# we see that NOX have highest negative prediction\n",
    "# and river, and rm have highest predictive value\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "n_features = len(feature_names)\n",
    "\n",
    "pl.barh(range(n_features), w, align='center')\n",
    "pl.yticks(np.arange(n_features), feature_names)\n",
    "pl.xlabel(\"Coefficient Value\")\n",
    "pl.ylabel(\"Feature Names\")\n",
    "pl.ylim(-1, n_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a164b1cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also plot the predicted values against the y values\n",
    "\n",
    "%matplotlib inline\n",
    "pl.plot(p, y,'ro') # ro just means dots will show up as red circles\n",
    "pl.plot([0,1],[0,1], 'b-') # this plots a straight line where b- means the line will be blue\n",
    "pl.xlabel('predicted values')\n",
    "pl.ylabel('actual values')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perform 10-fold cross-validation and compare the cross-validation RMSE to the training RMSE \n",
    "# (for cross validation, you should use the KFold module from sklearn.cross_validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "kf = KFold(n_splits=n, random_state=None, shuffle=False)\n",
    "\n",
    "# initialize the error to 0 - then we will add the errors and find the average\n",
    "# each time we go through the loop we find the RMSE on that particular fold\n",
    "# build a separate model on each different part of the training data and then compute RMSE each time\n",
    "xval_err = 0\n",
    "for train,test in kf.split(x):\n",
    "    w = standRegres(x[train],y[train]) # calling our linear regression function on x and y - training data\n",
    "    xMat = np.mat(x[test])\n",
    "    yMat = np.mat(y[test])\n",
    "    yHat = xMat*w # but predicting values using our test data\n",
    "    p = yHat.A.ravel() \n",
    "    # get error\n",
    "    err = abs(p - y[test])\n",
    "    # Comput RMSE\n",
    "    xval_err += np.sqrt(np.dot(err,err)/len(x[test]))\n",
    "       \n",
    "rmse_10cv = xval_err/n # this gives the average of the 10 RMSE values of each of the folds pair of sets of indices, not actual values - the indexes from the training data that corresponds to target\n",
    "# gives you ten of these pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression using method from Ch.8 of text\n",
      "RMSE on full training data: 0.1275\n",
      "RMSE on 10-fold CV: 0.1360\n"
     ]
    }
   ],
   "source": [
    "# comparing our rmse value\n",
    "# with the 10 fold rmse value:\n",
    "\n",
    "method_name = 'Simple Linear Regression using method from Ch.8 of text'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on full training data: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the values are very similar when I compute the averate of 10 RMSE values although the rmse_train is slightly lower for this regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Feature Selection:  \n",
    "use the scikit-learn regression model from sklearn.linear_model with a subset of features to perform linear regression. For feature selection, write a script or function that takes as input the training data, target variable; the model; and any other parameters you find necessary, and returns the optimal percentage of the most informative features to use. Your approach should use k-fold cross-validation on the training data (you can use k=5). You can use feature_selection.SelectPercentile to find the most informative variables. Show the list of most informative variables and their weights [Note: since this is regression not classification, you should use feature_selection.f_regression as scoring function rather than chi2). Next, plot the model's mean absolute error values  on cross-validation relative to the percentage of selected features (See scikit-learn's metrics.mean_absolute_error). In order to use cross_validation.cross_val_score with regression you'll need to pass to it scoring='mean_absolute_error' as a parameter. [Hint: for an example of a similar feature selection process please review the class example notebook. Also, review scikit-learn documentation for feature selection.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection chooses the top 30% of the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) For feature selection, write a script or function that takes as input the training data, target variable; \n",
    "# the model; and any other parameters you find necessary, \n",
    "# and returns the optimal percentage of the most informative features to use.\n",
    "\n",
    "# Your approach should use k-fold cross-validation on the training data (you can use k=5). \n",
    "# You can use feature_selection.SelectPercentile to find the most informative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a script or function that \n",
    "# returns the optimal percentage of the most informative features to use\n",
    "\n",
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 racepctblack           992.164385085\n",
      "   2 racePctWhite           1304.88061383\n",
      "   3 medIncome              341.309573516\n",
      "   4 pctWInvInc              761.05683978\n",
      "   5 pctWPubAsst            783.224359215\n",
      "   6 medFamInc              374.434695711\n",
      "   7 NumUnderPov            361.959402339\n",
      "   8 PctPopUnderPov         569.485853542\n",
      "   9 PctLess9thGrade        296.032041706\n",
      "  10 PctNotHSGrad           461.057792092\n",
      "  11 PctUnemployed          532.361633675\n",
      "  12 MalePctDivorce         580.342014438\n",
      "  13 FemalePctDiv           693.862699209\n",
      "  14 TotalPctDiv            677.228658531\n",
      "  15 PctFam2Par             1596.83916991\n",
      "  16 PctKids2Par            1901.30015001\n",
      "  17 PctYoungKids2Par       1269.98246619\n",
      "  18 PctTeen2Par            1231.32079315\n",
      "  19 NumIlleg               399.827842779\n",
      "  20 PctIlleg               1856.84970112\n",
      "  21 PctLargHouseFam        240.008616471\n",
      "  22 PctPersOwnOccup        600.098573515\n",
      "  23 PctPersDenseHous       348.808090558\n",
      "  24 PctHousLess3BR         446.478289592\n",
      "  25 MedNumBR               237.213726397\n",
      "  26 HousVacant             314.724917132\n",
      "  27 PctHousOwnOcc          448.758714138\n",
      "  28 PctVacantBoarded       489.301194335\n",
      "  29 PctHousNoPhone         485.842081804\n",
      "  30 NumInShelters          246.134719182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: divide by zero encountered in divide\n",
      "  corr /= X_norms\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:303: RuntimeWarning: invalid value encountered in divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=30) \n",
    "# what this does is use a particular\n",
    "# method to try to determine the x% of the features - so I need to specify the method, and the percentile\n",
    "# so this will select the top 30% features\n",
    "# using f regression\n",
    "\n",
    "# performing fit_transform on training data, and training target value\n",
    "x_fs = fs.fit_transform(x, y) # only uses 30% of the features\n",
    "\n",
    "# prints out the labels of the actual values that were chosen\n",
    "# and the values for those labels\n",
    "count = 1\n",
    "for i in range(len(feature_names)):\n",
    "    if fs.get_support()[i]:\n",
    "        print(\"{:4} {:20} {: >15}\".format(count, feature_names[i], fs.scores_[i]))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "# this is where that K-fold function comes in:\n",
    "# performing KFold using LinearRegression() from scikit learn\n",
    "# create the model\n",
    "linreg = LinearRegression()\n",
    "# fit the model\n",
    "# or in other words, train the model using the training sets\n",
    "linreg.fit(x,y)\n",
    "p = linreg.predict(x) # is our array of predictions\n",
    "err = abs(p - y)\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "#KFold using LinearRegression\n",
    "\n",
    "n = 10\n",
    "\n",
    "kf = KFold(n_splits=n, random_state=None, shuffle=False)\n",
    "\n",
    "# initialize the error to 0 - then we will add the errors and find the average\n",
    "# each time we go through the loop we find the RMSE on that particular fold\n",
    "# build a separate model on each different part of the training data and then compute RMSE each time\n",
    "xval_err = 0\n",
    "for train,test in kf.split(x):\n",
    "    linreg.fit(x[train],y[train]) # calling our linear regression function on x and y - training data\n",
    "    p = linreg.predict(x[test])\n",
    "    e = p-y[test] # now compute the error predicted value minus actual target value - don't need abs value b/c squaring\n",
    "    # now accumulate these error values by computing RMSE:\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(x[test]))\n",
    "    # now accumulate these error values by computing RMSE:\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(x[test]))\n",
    "rmse_cv = xval_err/n # this gives the average of the k RMSE values of each of the folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the measure_performance - to measure performance of our model\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#again, this was written for classification, with decision tree model\n",
    "# but we will be performing regression so we may want to consider making a simplified\n",
    "# version of this - that doesn't have any of the classification reports or show_accuracy etc.\n",
    "#\n",
    "def measure_performance(X, y, model):\n",
    "    y_pred = model.predict(X) \n",
    "    # still call the predict - except the model is linear regression\n",
    "    # so can use the y and y_pred for finding the mean absolute error in metrics model\n",
    "    return metrics.mean_absolute_error(y, y_pred)\n",
    "    # then you can get the mean_absolute_error whenever you need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.090729326782482758"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is giving us error vs accuracy so we see we have 0.09 error rate before feature selection\n",
    "measure_performance(x,y,linreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.095959506507870829"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after feature selection error rate:\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x_fs, y)\n",
    "x_test_fs = fs.transform(x_test)\n",
    "measure_performance(x_test_fs, y_test, linreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that the error rate actually goes up slightly when I did feature selection...maybe I made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do feature selection more systematically, we need to find the best percentile using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Next, plot the model's mean absolute error values on cross-validation relative \n",
    "#  to the percentage of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.113116874233\n",
      "6 0.101617711231\n",
      "11 0.101436113868\n",
      "16 0.101511882933\n",
      "21 0.0994790101435\n",
      "26 0.097616511133\n",
      "31 0.0976571054284\n",
      "36 0.0972626594836\n",
      "41 0.0969453231818\n",
      "46 0.0976809237359\n",
      "51 0.0978952487693\n",
      "56 0.098451490184\n",
      "61 0.0986872597973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/metrics/scorer.py:100: DeprecationWarning: Scoring method mean_absolute_error was renamed to neg_mean_absolute_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 0.09895147257\n",
      "71 0.0990267242825\n",
      "76 0.0986919326303\n",
      "81 0.098677987626\n",
      "86 0.0981388888819\n",
      "91 0.0975938826755\n",
      "96 0.0974049416263\n",
      "Optimal percentile of features:[41] \n",
      "\n",
      "Optimal number of features:40 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a18d9c750>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16816a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finding the best percentile:\n",
    "from sklearn import cross_validation\n",
    "\n",
    "percentiles = range(1, 100, 5) # experiment with different percentiles\n",
    "percentiles = np.array(percentiles) # wow, I added this b/c it was not working with just an array\n",
    "results = []\n",
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "for i in range(1, 100, 5): # iterates over these values - so with each one of these values do:\n",
    "\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(x, y)\n",
    "    scores = cross_validation.cross_val_score(linreg, X_train_fs, y, cv=5, scoring='mean_absolute_error') # cross-validation for only 5 folds\n",
    "    # for regression, we would want to return mean absolute error\n",
    "    # so in the above function, we want to add a parameter \n",
    "    # get negative numbers so need to use absolute value\n",
    "    scores = np.absolute(scores)\n",
    "    \n",
    "    print i,scores.mean() # compute the mean for this percentage\n",
    "    results = np.append(results, scores.mean()) # add this to the results list\n",
    "\n",
    "optimal_percentile = np.where(results == results.min())[0] \n",
    "print \"Optimal percentile of features:{0}\".format(percentiles[optimal_percentile]), \"\\n\"\n",
    "optimal_num_features = int(percentiles[optimal_percentile]*len(feature_names)/100)\n",
    "print \"Optimal number of features:{0}\".format(optimal_num_features), \"\\n\"\n",
    "\n",
    "# Plot percentile of features VS. cross-validation scores\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "pl.xlabel(\"Percentage of features selected\")\n",
    "pl.ylabel(\"Mean absolute error\")\n",
    "pl.plot(percentiles,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks like the optimal percentage of features is right around 35%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Next, perform Ridge Regression and Lasso Regression using the modules from sklearn.linear_model. In each case, perform systematic model selection to identify the optimal alpha parameter. First, create a 20%-80% randomized split of the data. Set aside the test portion; the model selection process should be performed using the 80% training data partition. You should create a function that takes as input the data and target variable; the parameter to vary and a list of its values; the model to be trained; and any other relevant input needed to determine the optimal value for the specified parameter. The model selection process should perform k-fold cross validation (k should be a parameter, but you can select k=5 for this problem). You should also plot the error values on the training and cross-validation splits across the specified values of the alpha parameter. Finally, using the best alpha value, run the model on the set-aside test data. Discuss your observation and conclusions. [Hint: for an example of a similar model selection process please review the class example notebook.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I already split the data above at the top of this notebook, so I can use these sets below I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "# using lambda in the slides but scikit learn uses alpha\n",
    "\n",
    "# Create linear regression object with a ridge coefficient (alpha)0.5\n",
    "# just like linear - call the Ridge constructor\n",
    "ridge = Ridge(fit_intercept=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training set - using training matrix(x) and target values(y) as before\n",
    "ridge.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE on training data - similar to linear regression\n",
    "p = ridge.predict(x) # find predictions based on the entire training data set\n",
    "err = p-y # error is predicted values minus target actual values\n",
    "total_error = np.dot(err,err) # sum of squared values is the total error\n",
    "rmse_train = np.sqrt(total_error/len(p)) # root mean squared error value formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Ridge Regression\n",
      "RMSE on training: 0.1313\n",
      "RMSE on 10-fold CV: 0.1360\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE using 10-fold x-validation with ridge regression\n",
    "\n",
    "\n",
    "n = 10\n",
    "kf = KFold(len(x), n_folds=n)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    ridge.fit(x[train],y[train])\n",
    "    p = ridge.predict(x[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(x[test]))\n",
    "rmse_10cv = xval_err/n\n",
    "\n",
    "method_name = 'Ridge Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# make this a function that takes as input \n",
    "# the data and target variable; the parameter to vary and a list of its values; \n",
    "# the model to be trained; and any other relevant input needed to determine the optimal value \n",
    "# for the specified parameter\n",
    "\n",
    "# this is the function that measure_performance can be called from within it\n",
    "\n",
    "\n",
    "def calc_params(x, y, model, param_values, param_name, K): \n",
    "    # takes data matrix, test, model that we're evaluating,\n",
    "    # range of values for parameter - ie. alpha values,\n",
    "    # parameter name, and K for k-fold cross validation\n",
    "    \n",
    "    # Convert input to Numpy arrays - would also work with pandas dataframes \n",
    "    X = np.array(x) # training scores\n",
    "    y = np.array(y) # testing stores\n",
    "\n",
    "    # initialize training and testing scores with zeros\n",
    "    # maintaining set of training scores and test scores as np.arrays\n",
    "    train_scores = np.zeros(len(param_values))\n",
    "    test_scores = np.zeros(len(param_values))\n",
    "    \n",
    "    # iterate over the different parameter values\n",
    "    for i, param_value in enumerate(param_values):\n",
    "        print param_name, ' = ', param_value\n",
    "        \n",
    "        # set classifier parameters\n",
    "        model.set_params(**{param_name:param_value}) \n",
    "        # pass a parameter name: parameter value \n",
    "        # ** allows for multiple values\n",
    "        # here we will be looking at different alpha values so 'alpha'= param_value\n",
    "        \n",
    "        # initialize the K scores obtained for each fold\n",
    "        k_train_scores = np.zeros(K)\n",
    "        k_test_scores = np.zeros(K)\n",
    "        \n",
    "        # create KFold cross validation\n",
    "        cv = KFold(len(x), K, shuffle=True, random_state=0) # set shuffle to true so it's random\n",
    "        \n",
    "        # iterate over the K folds\n",
    "        # call the fit function on the portion of the training data\n",
    "        for j, (train, test) in enumerate(cv):\n",
    "            # fit the classifier in the corresponding fold\n",
    "            # and obtain the corresponding error scores on train and test sets\n",
    "            model.fit([x[k] for k in train], y[train])\n",
    "            \n",
    "            # 1) below, rather than doing model.score, we can call the measure_performance function.\n",
    "            # so pass x[train], y[train], the linear regression model - in our situation \n",
    "            k_train_scores[j] = measure_performance(x[train], y[train], model) # don't need to create\n",
    "            # a list comprehension here - can just use x[train] - b/c train is already our index for our\n",
    "            # training instances in x for this particular K in the k fold val.\n",
    "            # we also compute test instances\n",
    "            k_test_scores[j] = measure_performance(x[test], y[test], model)\n",
    "            \n",
    "        # store the mean of the K fold scores\n",
    "        # then compute the means\n",
    "        train_scores[i] = np.mean(k_train_scores)\n",
    "        test_scores[i] = np.mean(k_test_scores)\n",
    "       \n",
    "    # plot the training and testing scores in a log scale\n",
    "    plt.plot(param_values, train_scores, label='Train', alpha=0.4, lw=2, c='b')\n",
    "    plt.plot(param_values, test_scores, label='X-Val', alpha=0.4, lw=2, c='g')\n",
    "    plt.legend(loc=7)\n",
    "    plt.xlabel(param_name + \" values\")\n",
    "    plt.ylabel(\"Mean cross validation accuracy\")\n",
    "\n",
    "    # return the training and testing scores on each parameter value\n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-02   4.17959184e-01   8.25918367e-01   1.23387755e+00\n",
      "   1.64183673e+00   2.04979592e+00   2.45775510e+00   2.86571429e+00\n",
      "   3.27367347e+00   3.68163265e+00   4.08959184e+00   4.49755102e+00\n",
      "   4.90551020e+00   5.31346939e+00   5.72142857e+00   6.12938776e+00\n",
      "   6.53734694e+00   6.94530612e+00   7.35326531e+00   7.76122449e+00\n",
      "   8.16918367e+00   8.57714286e+00   8.98510204e+00   9.39306122e+00\n",
      "   9.80102041e+00   1.02089796e+01   1.06169388e+01   1.10248980e+01\n",
      "   1.14328571e+01   1.18408163e+01   1.22487755e+01   1.26567347e+01\n",
      "   1.30646939e+01   1.34726531e+01   1.38806122e+01   1.42885714e+01\n",
      "   1.46965306e+01   1.51044898e+01   1.55124490e+01   1.59204082e+01\n",
      "   1.63283673e+01   1.67363265e+01   1.71442857e+01   1.75522449e+01\n",
      "   1.79602041e+01   1.83681633e+01   1.87761224e+01   1.91840816e+01\n",
      "   1.95920408e+01   2.00000000e+01]\n"
     ]
    }
   ],
   "source": [
    "# evenly spaced range of numbers in a specified interval for alpha \n",
    "alpha_vals = np.linspace(.01,20,50) \n",
    "\n",
    "print alpha_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha  =  0.01\n",
      "alpha  =  0.417959183673\n",
      "alpha  =  0.825918367347\n",
      "alpha  =  1.23387755102\n",
      "alpha  =  1.64183673469\n",
      "alpha  =  2.04979591837\n",
      "alpha  =  2.45775510204\n",
      "alpha  =  2.86571428571\n",
      "alpha  =  3.27367346939\n",
      "alpha  =  3.68163265306\n",
      "alpha  =  4.08959183673\n",
      "alpha  =  4.49755102041\n",
      "alpha  =  4.90551020408\n",
      "alpha  =  5.31346938776\n",
      "alpha  =  5.72142857143\n",
      "alpha  =  6.1293877551\n",
      "alpha  =  6.53734693878\n",
      "alpha  =  6.94530612245\n",
      "alpha  =  7.35326530612\n",
      "alpha  =  7.7612244898\n",
      "alpha  =  8.16918367347\n",
      "alpha  =  8.57714285714\n",
      "alpha  =  8.98510204082\n",
      "alpha  =  9.39306122449\n",
      "alpha  =  9.80102040816\n",
      "alpha  =  10.2089795918\n",
      "alpha  =  10.6169387755\n",
      "alpha  =  11.0248979592\n",
      "alpha  =  11.4328571429\n",
      "alpha  =  11.8408163265\n",
      "alpha  =  12.2487755102\n",
      "alpha  =  12.6567346939\n",
      "alpha  =  13.0646938776\n",
      "alpha  =  13.4726530612\n",
      "alpha  =  13.8806122449\n",
      "alpha  =  14.2885714286\n",
      "alpha  =  14.6965306122\n",
      "alpha  =  15.1044897959\n",
      "alpha  =  15.5124489796\n",
      "alpha  =  15.9204081633\n",
      "alpha  =  16.3283673469\n",
      "alpha  =  16.7363265306\n",
      "alpha  =  17.1442857143\n",
      "alpha  =  17.552244898\n",
      "alpha  =  17.9602040816\n",
      "alpha  =  18.3681632653\n",
      "alpha  =  18.776122449\n",
      "alpha  =  19.1840816327\n",
      "alpha  =  19.5920408163\n",
      "alpha  =  20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a092b0510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores, test_scores = calc_params(x, y, ridge, alpha_vals, 'alpha', 5)\n",
    "# calling calc_params to test various alpha vals using our ridge model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Ridge Regression, there is convergence around 2.5 to maybe 7.5 alpha value, but then there may be leveling off. As values get higher, we may be getting overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.092893257901221479"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking our accuracy with val 7.5\n",
    "ridge.set_params(alpha=7.5)\n",
    "\n",
    "ridge.fit(x, y)\n",
    "measure_performance(x_test, y_test, ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks pretty accurate with a low error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "# Create linear regression object with a ridge coefficient (alpha)0.5\n",
    "# just like linear - call the Ridge constructor\n",
    "lasso  = Lasso(fit_intercept=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training set \n",
    "lasso.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE on training data\n",
    "p = lasso.predict(x) # find predictions based on the entire training data set\n",
    "err = p-y # error is predicted values minus target actual values\n",
    "total_error = np.dot(err,err) # sum of squared values is the total error\n",
    "rmse_train = np.sqrt(total_error/len(p)) # root mean squared error value formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Lasso Regression\n",
      "RMSE on training: 0.2297\n",
      "RMSE on 10-fold CV: 0.2294\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE using 10-fold x-validation with ridge regression\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "\n",
    "n = 10\n",
    "kf = KFold(len(x), n_folds=n)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    lasso.fit(x[train],y[train])\n",
    "    p = lasso.predict(x[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.sqrt(np.dot(e,e)/len(x[test]))\n",
    "rmse_10cv = xval_err/n\n",
    "\n",
    "method_name = 'Lasso Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lasso, I see a higher error rate than ridge for 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha  =  0.01\n",
      "alpha  =  0.417959183673\n",
      "alpha  =  0.825918367347\n",
      "alpha  =  1.23387755102\n",
      "alpha  =  1.64183673469\n",
      "alpha  =  2.04979591837\n",
      "alpha  =  2.45775510204\n",
      "alpha  =  2.86571428571\n",
      "alpha  =  3.27367346939\n",
      "alpha  =  3.68163265306\n",
      "alpha  =  4.08959183673\n",
      "alpha  =  4.49755102041\n",
      "alpha  =  4.90551020408\n",
      "alpha  =  5.31346938776\n",
      "alpha  =  5.72142857143\n",
      "alpha  =  6.1293877551\n",
      "alpha  =  6.53734693878\n",
      "alpha  =  6.94530612245\n",
      "alpha  =  7.35326530612\n",
      "alpha  =  7.7612244898\n",
      "alpha  =  8.16918367347\n",
      "alpha  =  8.57714285714\n",
      "alpha  =  8.98510204082\n",
      "alpha  =  9.39306122449\n",
      "alpha  =  9.80102040816\n",
      "alpha  =  10.2089795918\n",
      "alpha  =  10.6169387755\n",
      "alpha  =  11.0248979592\n",
      "alpha  =  11.4328571429\n",
      "alpha  =  11.8408163265\n",
      "alpha  =  12.2487755102\n",
      "alpha  =  12.6567346939\n",
      "alpha  =  13.0646938776\n",
      "alpha  =  13.4726530612\n",
      "alpha  =  13.8806122449\n",
      "alpha  =  14.2885714286\n",
      "alpha  =  14.6965306122\n",
      "alpha  =  15.1044897959\n",
      "alpha  =  15.5124489796\n",
      "alpha  =  15.9204081633\n",
      "alpha  =  16.3283673469\n",
      "alpha  =  16.7363265306\n",
      "alpha  =  17.1442857143\n",
      "alpha  =  17.552244898\n",
      "alpha  =  17.9602040816\n",
      "alpha  =  18.3681632653\n",
      "alpha  =  18.776122449\n",
      "alpha  =  19.1840816327\n",
      "alpha  =  19.5920408163\n",
      "alpha  =  20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18d7f910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores, test_scores = calc_params(x, y, lasso, alpha_vals, 'alpha', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18311537941465963"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure what's going on here!  Looks like a mistake from the looks of the graph...\n",
    "# checking our accuracy with val 2.5\n",
    "lasso.set_params(alpha=2.5)\n",
    "\n",
    "lasso.fit(x, y)\n",
    "measure_performance(x_test, y_test, lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure how to discuss this performance b/c it looks like a bug..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Next, perform regression using Stochastic Gradient Descent for regression. For this part, you should use the SGDRegessor module from sklearn.linear_model. Again, start by a creating randomized 80%-20% train-test split. SGDRegessor requires that features be standardized (with 0 mean and scaled by standard deviation). Prior to fiting the model, perform the scaling using StandardScaler from sklearn.preprocessing. For this problem, perform a grid search (using GridSearchCV from sklearn.grid_search) Your grid search should compare combinations of two penalty parameters ('l2', 'l1') and different values of alpha (alpha could vary from 0.0001 which is the default to relatively large values, say 10). Using the best parameters, apply the model to the set-aside test data. Finally, perform model selection (similar to part d, above) to find the best \"l1_ratio\" parameter using SGDRegressor with  the \"elasticnet\" penalty parameter. [Note: \"l1_ratio\" is The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1;  l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1 penalty; defaults to 0.15.] Using the best mixing ratio, apply the Elastic Net model to the set-aside test data. Provide a summary of your findings from the above experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Stochastic Gradient Descent Regression\n",
      "RMSE on training: 0.1313\n",
      "RMSE on 10-fold CV: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SGD is very senstitive to varying-sized feature values. So, first we need to do feature scaling.\n",
    "# basically same as others but internally we are doing optimization method - iterative,\n",
    "# so not trying to get the exact solution\n",
    "# also b/c doing optimization on individual instances in the data - it is fairly efficient\n",
    "# but you do have to do a number of iterations b/f you start converging on reasonable values with SGD conversion\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# do this b/c is sensitive to varying sized values \n",
    "# this is good practice to standardize the data particularly with sgd\n",
    "\n",
    "# standardize the data:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_s = scaler.transform(x) # standard version of x matrix\n",
    "\n",
    "sgdreg = SGDRegressor(penalty='l2', alpha=0.1, n_iter=300) # this is how we build the model\n",
    "# penalty is l2 or l1 = sum of squared errors iteratively updating w values\n",
    "# can add to function regularization - ridge vs. lasso, can also add elastic net as option\n",
    "# alpha is 0.1 that professor specified\n",
    "# professor specified 300 iterations - is a good starting point\n",
    "\n",
    "\n",
    "# the rest is basically the same:\n",
    "# Compute RMSE on training data\n",
    "sgdreg.fit(x_s,y)\n",
    "p = sgdreg.predict(x_s)\n",
    "err = p-y\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "kf = KFold(len(x), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x[train])  # Don't cheat - fit only on training data\n",
    "    xtrain_s = scaler.transform(x[train])\n",
    "    xtest_s = scaler.transform(x[test])  # apply same transformation to test data\n",
    "    sgdreg.fit(xtrain_s,y[train])\n",
    "    p = sgdreg.predict(xtest_s)\n",
    "    e = p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "rmse_10cv = np.sqrt(xval_err/len(x))\n",
    "\n",
    "method_name = 'Stochastic Gradient Descent Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok I see that SGD has low error rate for both RMSE_training and RMSE 10-fold CV, \n",
    "# however the 10-fold CV is slightly higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search comparing l1 and l2, as well as different values of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-04   2.04179592e-01   4.08259184e-01   6.12338776e-01\n",
      "   8.16418367e-01   1.02049796e+00   1.22457755e+00   1.42865714e+00\n",
      "   1.63273673e+00   1.83681633e+00   2.04089592e+00   2.24497551e+00\n",
      "   2.44905510e+00   2.65313469e+00   2.85721429e+00   3.06129388e+00\n",
      "   3.26537347e+00   3.46945306e+00   3.67353265e+00   3.87761224e+00\n",
      "   4.08169184e+00   4.28577143e+00   4.48985102e+00   4.69393061e+00\n",
      "   4.89801020e+00   5.10208980e+00   5.30616939e+00   5.51024898e+00\n",
      "   5.71432857e+00   5.91840816e+00   6.12248776e+00   6.32656735e+00\n",
      "   6.53064694e+00   6.73472653e+00   6.93880612e+00   7.14288571e+00\n",
      "   7.34696531e+00   7.55104490e+00   7.75512449e+00   7.95920408e+00\n",
      "   8.16328367e+00   8.36736327e+00   8.57144286e+00   8.77552245e+00\n",
      "   8.97960204e+00   9.18368163e+00   9.38776122e+00   9.59184082e+00\n",
      "   9.79592041e+00   1.00000000e+01]\n"
     ]
    }
   ],
   "source": [
    "# evenly spaced range of numbers in a specified interval for alpha\n",
    "alpha_vals = np.linspace(.0001,10,50) \n",
    "\n",
    "print alpha_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'warm_start': False, 'loss': 'squared_loss', 'eta0': 0.01, 'verbose': 0, 'shuffle': True, 'fit_intercept': True, 'l1_ratio': 0.15, 'average': False, 'max_iter': None, 'penalty': 'l2', 'power_t': 0.25, 'random_state': None, 'tol': None, 'epsilon': 0.1, 'n_iter': 300, 'alpha': 0.1, 'learning_rate': 'invscaling'}\n"
     ]
    }
   ],
   "source": [
    "# looking at the parameters for sdg - we will be looking at 'penalty' l1 or l2\n",
    "# and different values of 'alpha'\n",
    "\n",
    "print sgdreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GridSearchCV to find ideal parameters\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'alpha': alpha_vals,\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(sgdreg, parameters, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 s, sys: 275 ms, total: 28.9 s\n",
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:   28.6s finished\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.0001, 'penalty': 'l2'}, 0.6423797495760898)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for best parameters and best score\n",
    "# we're using sgdreg on our standardized x: x_s\n",
    "\n",
    "%time _ = gs.fit(x_s, y)\n",
    "\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking 'l1'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'alpha': alpha_vals,\n",
    "    'penalty': ['l1']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(sgdreg, parameters, verbose=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:  1.3min finished\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 501 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.0001, 'penalty': 'l1'}, 0.6383917910085288)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time _ = gs.fit(x_s, y)\n",
    "\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it appears from both tests above that alpha = 0.0001 is the best alpha value, and 'l1' give us a higher accuracy \n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best parameters, apply the model to the set-aside test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14313113979681874"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the params to the set aside test data\n",
    "# alpha = 0.0001\n",
    "sgdreg.set_params(alpha=0.0001,penalty='l1')\n",
    "\n",
    "sgdreg.fit(x_s, y)\n",
    "measure_performance(x_test, y_test, sgdreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still very low error rate using sgdreg with these parameters, compared with our other models above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, perform model selection (similar to part d, above) to find the best \"l1_ratio\" \n",
    "# parameter using SGDRegressor with the \"elasticnet\" penalty parameter. \n",
    "# [Note: \"l1_ratio\" is The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1; \n",
    "# l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1 penalty; defaults to 0.15.] \n",
    "# Using the best mixing ratio, apply the Elastic Net model to the set-aside test data. \n",
    "# Provide a summary of your findings from the above experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for l1_ratio parameter:\n",
    "l1_ratio_vals = np.linspace(0,1,25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.0416666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.0833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.208333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.291666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.416666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.458333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.541666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.583333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.708333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.791666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.916666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.958333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103913b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores, test_scores = calc_params(x, y, sgdreg, l1_ratio_vals, 'l1_ratio', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmmmm, another strange looking visualization!  I'll just guess a value, so I'll choose 0.8 as the parameter\n",
    "# because they seem to converge slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normalize': False, 'warm_start': False, 'selection': 'cyclic', 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'precompute': False, 'random_state': None, 'tol': 0.0001, 'positive': False, 'copy_X': True, 'alpha': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# applying the params to the set aside test data\n",
    "# with l1_ration\n",
    "elastic_net = ElasticNet(fit_intercept=True)\n",
    "\n",
    "print elastic_net.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18311537941465963"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_net.set_params(l1_ratio=0.8)\n",
    "\n",
    "elastic_net.fit(x, y)\n",
    "measure_performance(x_test, y_test, elastic_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see that the elastic_net model gives us a higher error value than SDG, and the same value for lasso\n",
    "# whereas our ridge value had a much lower error rate at ~0.09, as did linreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Automatic Document Clustering [Dataset: newsgroups5.zip]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem you will use a different subset of the 20 Newsgroup data set that you used in Assignment 2  (see the description of the full dataset). The subset for this assignment includes 2,500 documents (newsgroup posts), each belonging to one of 5 categories windows (0), crypt (1), christian (2), hockey (3), forsale (4). The documents are represented by 9328 terms (stems). The dictionary (vocabulary) for the data set is given in the file \"terms.txt\" and the full term-by-document matrix is given in \"matrix.txt\" (comma separated values). The actual category labels for the documents are provided in the file \"classes.txt\". Your goal in this assignment is to perform clustering on the documents and compare the clusters to the actual categories.\n",
    "\n",
    "Your tasks in this problem are the following [Note: for the clustering part of this assignment you should use the kMeans module form Ch. 10 of MLA (use the version provided here as it includes some corrections to the book version). You may also use Pandas and other modules from scikit-learn that you may need for preprocessing or evaluation.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. This is the distance function you will use to pass to the kMeans function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the book's implementation of Euclidean distance\n",
    "# def distEuclid(vecA, vecB):\n",
    "#     return sqrt(sum(power(vecA - vecB, 2))) #la.norm(vecA-vecB)\n",
    "\n",
    "# we need to create Cosine similarity function to use as our similarity metric that takes in two vectors \n",
    "def distCosine(vecA, vecB):\n",
    "    # using cosine similarity to compare two vectors\n",
    "    # first compute norm of each one of the rows\n",
    "    A_norm = np.linalg.norm(vecA)\n",
    "    B_norm = np.linalg.norm(vecB)\n",
    "    # then we divide the dot product of our two vectors by the norms of each vector multiplied:\n",
    "    sim = np.dot(vecA,vecB)/(A_norm * B_norm)\n",
    "    # this total calculation gives us cosine similarity between our two vectors\n",
    "    # so we now need to subtract our value from 1 to find the distance needed for our kmeans function\n",
    "    # inverse of the similarity\n",
    "    distance = 1 - sim\n",
    "    return distance\n",
    "\n",
    "# now I'll add this to the kmeans.py file so it can be called in our clustering function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Load the data set [Note: the data matrix provided has terms as rows and documents as columns. Since you will be clustering documents, you'll need to take the transpose of this matrix so that your main data matrix is a document x term matrix. In Numpy, you may use the \".T\" operation to obtain the transpose.] Then, split the data set (the document x term matrix) and set aside 20% for later use (see below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data \n",
    "data = pd.read_csv(\"newsgroups5/matrix.txt\", header=None, sep=',', na_values=[\"?\", \" \"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9328, 2500)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # term X document dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if any nan values\n",
    "nans_rows = data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 2500 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't look like there are any null or nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because our kNN classifier uses numpy array or matrix as input, we need to transform DataFrames into np arrays\n",
    "# and we need to transpose so that they are document/text matrixes\n",
    "\n",
    "# training data into np.array\n",
    "data = np.array(data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 9328)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # we now have a document X term 2D np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.loadtxt('newsgroups5/classes.txt', delimiter=' ', skiprows=1, usecols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now we need to split the data into training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, target, target_test = train_test_split(data,target, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9328)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9328)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Perform Kmeans clustering on the training data. Write a function to display the top N terms in each cluster along with the cluster DF values for each term and the size of the cluster. The cluster DF value for a term t in a cluster C is the percentage of docs in cluster C in which term t appears (so, if a cluster has 500 documents, and term \"game\" appears in 100 of those 500 documents, then DF value of \"game\" in that cluster is 0.2 or 20%). Sort the terms for each cluster in decreasing order of the DF percentage. Here is an example of how this output might look like (here the top 10 terms for 3 of the 5 clusters are displayed in decreasing order of cluster DF values, but the mean frequnecy from the cluster centroid is also shown). [Extra Credit: use your favorite third party tool, ideally with a Python based API, to create a word cloud for each cluster.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terms are the columns indexes, I'm assuming in order so I'll read in the terms here\n",
    "\n",
    "terms = np.genfromtxt('newsgroups5/terms.txt',dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9328,)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perform kmeans clustering on the training data:\n",
    "# import the kmeans alg \n",
    "\n",
    "import kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kMeans' from 'kMeans.pyc'>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(kMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids, clusters = kMeans.kMeans(x_train, 5, kMeans.distCosine, kMeans.randCent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.85714286e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          2.85714286e-01,   1.42857143e-01,   8.57142857e-01],\n",
       "       [  8.08843989e-01,   2.39244214e-01,   4.40107761e+01, ...,\n",
       "          1.14424574e+00,   6.66995939e-01,   3.62800448e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          1.66666667e-01,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   9.92555831e-03,   2.48138958e-03, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  3.15656566e-03,   0.00000000e+00,   4.54545455e-02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids \n",
    "# these values show us the mean frequency of raw counts in the documents\n",
    "# these are our 5 centroids with the mean value for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9328)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape # so this is 5 by 9328 2D np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.        ,  0.80087285],\n",
       "       [ 4.        ,  0.75962926],\n",
       "       [ 4.        ,  0.72569189],\n",
       "       ..., \n",
       "       [ 4.        ,  0.34664739],\n",
       "       [ 4.        ,  0.50722438],\n",
       "       [ 4.        ,  0.56491376]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters # see notes below describing these numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape \n",
    "# we see that each row is referring to a document so we now have each document and its cluster assignment(first value)\n",
    "# second value is average distance to the center of the cluster\n",
    "# usually don't do anything with second column\n",
    "# just the first column is used to see cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tCluster0\tCluster1\tCluster2\tCluster3\tCluster4\n",
      "        aa\t0.2857\t\t0.8088\t\t0.0000\t\t0.0000\t\t0.0032\n",
      "     aargh\t0.0000\t\t0.2392\t\t0.0000\t\t0.0099\t\t0.0000\n",
      "     aaron\t0.0000\t\t44.0108\t\t0.0000\t\t0.0025\t\t0.0455\n",
      "    aaronc\t0.0000\t\t0.0773\t\t0.0000\t\t0.0000\t\t0.0051\n",
      "        ab\t1.5714\t\t2.0303\t\t0.1667\t\t0.0000\t\t0.0038\n",
      "   abandon\t0.0000\t\t0.7777\t\t0.0000\t\t0.0050\t\t0.0051\n",
      "       abc\t0.0000\t\t0.8700\t\t0.0000\t\t0.0993\t\t0.0025\n",
      "      abid\t0.0000\t\t0.2414\t\t0.0000\t\t0.0000\t\t0.0013\n",
      "      abil\t0.1429\t\t4.3413\t\t0.0000\t\t0.0199\t\t0.0316\n",
      "       abl\t0.0000\t\t3.7349\t\t0.0000\t\t0.0819\t\t0.0922\n"
     ]
    }
   ],
   "source": [
    "# looking at the centroids just for first 10 terms\n",
    "print \"\\t\\tCluster0\\tCluster1\\tCluster2\\tCluster3\\tCluster4\"\n",
    "for i in range(10):\n",
    "    print \"%10s\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\" %(terms[i],centroids[0][i],centroids[1][i],\n",
    "                                                         centroids[2][i],centroids[3][i],centroids[4][i])\n",
    "\n",
    "# This table shows us the mean frequency of raw counts of the specific term in the documents\n",
    "# for that cluster\n",
    "# seems to be capturing the patterns in the data\n",
    "# (if I have time I will look into word clouds)\n",
    "# for example, we see that aa appears on average 0.2857 times in cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now write a function to display the top N terms in each cluster along with the  \n",
    "# cluster DF values for each term and the size of the cluster.\n",
    "# The cluster DF value for a term t in a cluster C is the percentage of docs in cluster C \n",
    "# in which term t appears (so, if a cluster has 500 documents, and term \"game\" appears in 100 \n",
    "# of those 500 documents, then DF value of \"game\" in that cluster is 0.2 or 20%). \n",
    "# Sort the terms for each cluster in decreasing order of the DF percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will allow me to get the number of docs in each cluster:\n",
    "newC = clusters.T\n",
    "newC = newC[0, :]\n",
    "newC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  4.  4. ...,  4.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "print newC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I may need the total number of documents and total number of rows for my function:\n",
    "total_terms = len(x_train[0])\n",
    "total_docs = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "9328\n"
     ]
    }
   ],
   "source": [
    "print total_docs\n",
    "print total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have the mean frequency of the raw counts of the specific terms in the documents\n",
    "# and I have the cluster assignments for each document so I can create this function\n",
    "# finding the document frequency\n",
    "def displayClusters():\n",
    "    for i in range(5):\n",
    "        print \"Cluster {} results:\".format(i)\n",
    "        cluster_indx = [ind for ind,x in enumerate(newC[0,:]) if x==i]\n",
    "        num_docs = len(cluster_indx)\n",
    "        print \"Number of documents in cluster:  {}\".format(num_docs) \n",
    "        # here I need to figure out how to find the DF for each term...\n",
    "        # having a hard time figuring how to create my cluster lists\n",
    "#         arr = np.empty([0, total_terms])\n",
    "#         for ind, row in enumerate(x_train):\n",
    "#             for clust_ind in cluster_indx:\n",
    "#                 if ind==clust_ind:\n",
    "# #                     print clust_ind,row\n",
    "#                     arr = np.append(arr, [row], axis=0)\n",
    "        \n",
    "    \n",
    "#         print df\n",
    "    # now I can find the doc frequency\n",
    "\n",
    "#         DF = np.array([(arr!=0).sum(0)]).T\n",
    "        \n",
    "#         df = DF/num_docs # not giving me accurate percentages        \n",
    "# got stuck here and I'm out of time so I'm moving forward and will come back to this...\n",
    "# maybe I'm overcomplicating this\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 results:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-474-84c513166356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplayClusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-473-c8e6733baba9>\u001b[0m in \u001b[0;36mdisplayClusters\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Cluster {} results:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcluster_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnum_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Number of documents in cluster:  {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "displayClusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned classes by computing the Completeness and Homogeneity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761159274968\n"
     ]
    }
   ],
   "source": [
    "print completeness_score(target,newC) \n",
    "# that means all members of a given class are assigned to the same cluster\n",
    "# ideally these both should be high values\n",
    "# pass original target values, and our clustering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.257640697217\n"
     ]
    }
   ],
   "source": [
    "print homogeneity_score(target,newC) \n",
    "# means each clusters contain only members of a single class\n",
    "# often there is a tradeoff between these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oops, very low, maybe made a mistake somewhere..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Finally, using your cluster assignments as class labels, categorize each of the documents in the 20% set-aside data into each of the appropriate cluster. Your categorization should be based on Cosine similarity between each test document and cluster centroids. For each test document show the predicted class label as well as Cosine similarity to the corresponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the classification algorithm\n",
    "# using Rocchio as an outline\n",
    "def categoryClass(x, cents):\n",
    "    \"\"\" compare cosine-similarity for instance x between the prototypes \"\"\"\n",
    "    # first find the vector norm for each instance in prototypes as well as the norm for vector x\n",
    "    D_norm = np.array([np.linalg.norm(cents[i]) for i in range(len(cents))])\n",
    "    x_norm = np.linalg.norm(x)\n",
    "    # Compute Cosine: divide the dot product o x and each instance in D by the product of the two norms\n",
    "    sims = np.dot(cents,x)/(D_norm * x_norm)\n",
    "    # The distance measure will be the inverse of Cosine similarity\n",
    "    dists = 1 - sims\n",
    "    \n",
    "    # this gives us the index of the most similar centroids\n",
    "    idx = np.argsort(dists) # sorting\n",
    "        \n",
    "    return idx[0], dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revamping accuracy function from above\n",
    "def categoryAccuracy(testData, testLabels, cents):\n",
    "    # first get the length of the data we are testing for accuracy\n",
    "    numTestVecs = len(testData)\n",
    "    # initialize the error count to 0.0\n",
    "    errorCount = 0.0\n",
    "    # not test for accuracy for each vector in the test set using the known labels\n",
    "    for i in range(numTestVecs):\n",
    "        # call categoryClass for each vector in test data\n",
    "        prediction, distances = categoryClass(testData[i], cents)\n",
    "        # compare the predicted label with our known label\n",
    "        # if they are not equal then we add 1 to our error count\n",
    "        if (prediction != testLabels[i]): errorCount += 1.0\n",
    "    # the formula for error rate is the total error count divided by the number of \n",
    "    # our total test vectors or the length of the testData\n",
    "    errorRate = errorCount/float(numTestVecs)\n",
    "    print \"the total error rate is: %f\" % (errorRate)\n",
    "    return errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total error rate is: 0.624000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.624"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoryAccuracy(x_test, target_test, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well, it looks like my accuracy is not very good at all.  I will have to look over all of my work and see\n",
    "# where I went wrong.  I remember our professor saying that we need to recluster at some point.  I'm not sure\n",
    "# where that would need to be done.  For now I am turning in my assignment but I will continue to look into what went\n",
    "# wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
